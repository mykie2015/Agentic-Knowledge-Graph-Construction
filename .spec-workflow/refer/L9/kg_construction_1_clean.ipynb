{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 9 - Knowledge Graph Construction - Part I\n",
    "\n",
    "With all the plans in place, it's time to construct the knowledge graph.\n",
    "\n",
    "For the **domain graph** construction, no agent is required. The construction plan has all the information needed to drive a rule-based import.\n",
    "\n",
    "<img src=\"images/domain.png\" width=\"600\">\n",
    "\n",
    "**Note**: This notebook uses Cypher queries to build the domain graph from CSV files. Don't worry if you're unfamiliar with Cypher ‚Äî focus on understanding the big picture of how the structured data is transformed into a graph structure based on the construction plan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Overview\n",
    "\n",
    "This lesson demonstrates how to construct a domain knowledge graph from structured CSV data using:\n",
    "\n",
    "- **Input**: `approved_construction_plan` (from previous lessons)\n",
    "- **Output**: A domain graph in Neo4j with nodes and relationships\n",
    "- **Tools**: `construct_domain_graph` + helper functions\n",
    "\n",
    "**Workflow**:\n",
    "1. Load and validate the construction plan\n",
    "2. Create uniqueness constraints for data integrity\n",
    "3. Import nodes from CSV files\n",
    "4. Create relationships between nodes\n",
    "5. Verify the constructed graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Setup\n",
    "\n",
    "Import necessary libraries, load environment variables, and establish connection to Neo4j.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìã Quick Setup Instructions\n",
    "\n",
    "**If you encounter `ModuleNotFoundError`, install missing dependencies:**\n",
    "\n",
    "```bash\n",
    "# Install all required packages\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Or install individually\n",
    "pip install pandas>=2.0.0 numpy>=1.24.0\n",
    "```\n",
    "\n",
    "**Note**: pandas is only required for Option B (DataFrame import). Option A (CSV import) works without pandas if your Neo4j instance supports CSV loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ pandas imported successfully\n",
      "Core libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "from typing import Dict, Any\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Try to import pandas (needed only for Option B - DataFrame import)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    PANDAS_AVAILABLE = True\n",
    "    print(\"‚úÖ pandas imported successfully\")\n",
    "except ImportError:\n",
    "    PANDAS_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  pandas not available - Option B (DataFrame import) will not work\")\n",
    "    print(\"   Install with: pip install pandas>=2.0.0\")\n",
    "    print(\"   You can still use Option A (CSV import) if Neo4j import is configured\")\n",
    "\n",
    "# Suppress warnings and logging for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Core libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI connection established.\n"
     ]
    }
   ],
   "source": [
    "# Configure the language model\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM connection\n",
    "test_response = llm.llm_client.completion(\n",
    "    model=llm.model, \n",
    "    messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], \n",
    "    tools=[]\n",
    ")\n",
    "print(\"‚úÖ OpenAI connection established.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j Status: {'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n",
      "‚úÖ Neo4j connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "# Test Neo4j connection\n",
    "neo4j_status = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "print(f\"Neo4j Status: {neo4j_status}\")\n",
    "\n",
    "if neo4j_status['status'] == 'success':\n",
    "    print(\"‚úÖ Neo4j connection established successfully.\")\n",
    "else:\n",
    "    print(\"‚ùå Neo4j connection failed. Please check your configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. Neo4j Plugin Verification\n",
    "\n",
    "Check that required Neo4j plugins (especially APOC) are installed and available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CHECKING NEO4J PLUGINS\n",
      "==================================================\n",
      "‚úÖ APOC is installed - Version: 2025.08.0\n",
      "‚úÖ APOC text functions are available\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Check Neo4j components and plugins\n",
    "print(\"üîç CHECKING NEO4J PLUGINS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check APOC availability (needed for advanced text functions in later lessons)\n",
    "try:\n",
    "    apoc_check = graphdb.send_query(\"RETURN apoc.version() AS apoc_version\")\n",
    "    if apoc_check['status'] == 'success' and apoc_check['query_result']:\n",
    "        apoc_version = apoc_check['query_result'][0]['apoc_version']\n",
    "        print(f\"‚úÖ APOC is installed - Version: {apoc_version}\")\n",
    "        \n",
    "        # Test APOC text functions (needed for entity resolution in L10)\n",
    "        text_func_test = graphdb.send_query(\"RETURN apoc.text.jaroWinklerDistance('test', 'test') AS similarity\")\n",
    "        if text_func_test['status'] == 'success':\n",
    "            print(\"‚úÖ APOC text functions are available\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  APOC text functions may not be available\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  APOC is not installed (will be needed for L10)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  APOC is not installed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Core Functions for Domain Graph Construction\n",
    "\n",
    "These functions handle the creation of nodes and relationships from CSV data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniqueness_constraint(label: str, unique_property_key: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Creates a uniqueness constraint for a node label and property key.\n",
    "    \n",
    "    Args:\n",
    "        label: The label of the node to create a constraint for.\n",
    "        unique_property_key: The property key that should have a unique value.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with a status key ('success' or 'error').\n",
    "    \"\"\"\n",
    "    constraint_name = f\"{label}_{unique_property_key}_constraint\"\n",
    "    query = f\"\"\"CREATE CONSTRAINT `{constraint_name}` IF NOT EXISTS\n",
    "    FOR (n:`{label}`)\n",
    "    REQUIRE n.`{unique_property_key}` IS UNIQUE\"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = graphdb.send_query(query)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_nodes(node_construction: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Import nodes as defined by a node construction rule.\n",
    "    \n",
    "    Args:\n",
    "        node_construction: Dictionary containing node import configuration\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and any error messages\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First create the uniqueness constraint\n",
    "        constraint_result = create_uniqueness_constraint(\n",
    "            node_construction[\"label\"], \n",
    "            node_construction[\"unique_column_name\"]\n",
    "        )\n",
    "        \n",
    "        if constraint_result[\"status\"] == \"error\":\n",
    "            return constraint_result\n",
    "\n",
    "        # Then load nodes from CSV - simplified version without APOC dependency\n",
    "        properties = node_construction[\"properties\"]\n",
    "        unique_column = node_construction[\"unique_column_name\"]\n",
    "        label = node_construction[\"label\"]\n",
    "        \n",
    "        # Build SET clause for properties\n",
    "        set_clauses = [f\"n.{prop} = row.{prop}\" for prop in properties]\n",
    "        set_clause = \", \".join(set_clauses)\n",
    "        \n",
    "        query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "        CALL {{\n",
    "            WITH row\n",
    "            MERGE (n:{label} {{ {unique_column} : row.{unique_column} }})\n",
    "            SET {set_clause}\n",
    "        }} IN TRANSACTIONS OF 1000 ROWS\n",
    "        \"\"\"\n",
    "        \n",
    "        results = graphdb.send_query(query, {\n",
    "            \"source_file\": node_construction[\"source_file\"]\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_relationships(relationship_construction: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Import relationships as defined by a relationship construction rule.\n",
    "    \n",
    "    Args:\n",
    "        relationship_construction: Dictionary containing relationship configuration\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and any error messages\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from_node_column = relationship_construction[\"from_node_column\"]\n",
    "        to_node_column = relationship_construction[\"to_node_column\"]\n",
    "        from_label = relationship_construction[\"from_node_label\"]\n",
    "        to_label = relationship_construction[\"to_node_label\"]\n",
    "        rel_type = relationship_construction[\"relationship_type\"]\n",
    "        \n",
    "        query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "        CALL {{\n",
    "            WITH row\n",
    "            MATCH (from_node:{from_label} {{ {from_node_column} : row.{from_node_column} }}),\n",
    "                  (to_node:{to_label} {{ {to_node_column} : row.{to_node_column} }})\n",
    "            MERGE (from_node)-[r:{rel_type}]->(to_node)\n",
    "            SET r.created_at = datetime()\n",
    "        }} IN TRANSACTIONS OF 1000 ROWS\n",
    "        \"\"\"\n",
    "        \n",
    "        results = graphdb.send_query(query, {\n",
    "            \"source_file\": relationship_construction[\"source_file\"]\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_domain_graph(construction_plan: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Construct a domain graph according to a construction plan.\n",
    "    \n",
    "    Args:\n",
    "        construction_plan: Dictionary containing both node and relationship rules\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with construction results\n",
    "    \"\"\"\n",
    "    results = {\"nodes\": [], \"relationships\": []}\n",
    "    \n",
    "    # First, import nodes\n",
    "    print(\"üìä Creating nodes...\")\n",
    "    node_constructions = [value for value in construction_plan.values() \n",
    "                         if value['construction_type'] == 'node']\n",
    "    \n",
    "    for node_construction in node_constructions:\n",
    "        label = node_construction['label']\n",
    "        print(f\"  Creating {label} nodes...\")\n",
    "        result = import_nodes(node_construction)\n",
    "        results[\"nodes\"].append({\"label\": label, \"result\": result})\n",
    "        \n",
    "        if result[\"status\"] == \"error\":\n",
    "            print(f\"  ‚ùå Error creating {label}: {result['error_message']}\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ {label} nodes created successfully\")\n",
    "\n",
    "    # Second, import relationships\n",
    "    print(\"\\nüîó Creating relationships...\")\n",
    "    relationship_constructions = [value for value in construction_plan.values() \n",
    "                                 if value['construction_type'] == 'relationship']\n",
    "    \n",
    "    for relationship_construction in relationship_constructions:\n",
    "        rel_type = relationship_construction['relationship_type']\n",
    "        print(f\"  Creating {rel_type} relationships...\")\n",
    "        result = import_relationships(relationship_construction)\n",
    "        results[\"relationships\"].append({\"type\": rel_type, \"result\": result})\n",
    "        \n",
    "        if result[\"status\"] == \"error\":\n",
    "            print(f\"  ‚ùå Error creating {rel_type}: {result['error_message']}\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ {rel_type} relationships created successfully\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. Alternative: Direct Data Import Functions\n",
    "\n",
    "If Neo4j CSV import is not available, these functions provide an alternative approach using pandas DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nodes_from_dataframe(df, label, unique_property, properties):\n",
    "    \"\"\"\n",
    "    Create nodes directly from pandas DataFrame (alternative to CSV import).\n",
    "    \"\"\"\n",
    "    print(f\"  Creating {label} nodes from DataFrame...\")\n",
    "    \n",
    "    # Create constraint first\n",
    "    constraint_query = f\"CREATE CONSTRAINT IF NOT EXISTS FOR (n:{label}) REQUIRE n.{unique_property} IS UNIQUE\"\n",
    "    constraint_result = graphdb.send_query(constraint_query)\n",
    "    \n",
    "    # Create nodes in batches\n",
    "    nodes_created = 0\n",
    "    batch_size = 100\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Build MERGE statements for this batch\n",
    "        merge_statements = []\n",
    "        for _, row in batch.iterrows():\n",
    "            # Build property string\n",
    "            props = []\n",
    "            for prop in properties + [unique_property]:\n",
    "                if prop in row and pd.notna(row[prop]):\n",
    "                    value = row[prop]\n",
    "                    if isinstance(value, str):\n",
    "                        value = value.replace('\"', '\\\\\"')\n",
    "                        props.append(f'{prop}: \"{value}\"')\n",
    "                    else:\n",
    "                        props.append(f'{prop}: {value}')\n",
    "            \n",
    "            prop_string = \", \".join(props)\n",
    "            merge_statements.append(f\"MERGE (:{label} {{{prop_string}}})\")\n",
    "        \n",
    "        # Execute batch\n",
    "        if merge_statements:\n",
    "            batch_query = \"\\n\".join(merge_statements)\n",
    "            try:\n",
    "                result = graphdb.send_query(batch_query)\n",
    "                if result['status'] == 'success':\n",
    "                    nodes_created += len(merge_statements)\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ùå Batch error: {e}\")\n",
    "    \n",
    "    print(f\"    ‚úÖ Created {nodes_created} {label} nodes\")\n",
    "    return nodes_created\n",
    "\n",
    "\n",
    "def create_relationships_from_dataframe(df, from_label, from_column, to_label, to_column, rel_type):\n",
    "    \"\"\"\n",
    "    Create relationships directly from pandas DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"  Creating {rel_type} relationships from DataFrame...\")\n",
    "    \n",
    "    relationships_created = 0\n",
    "    batch_size = 50\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        rel_statements = []\n",
    "        for _, row in batch.iterrows():\n",
    "            if pd.notna(row[from_column]) and pd.notna(row[to_column]):\n",
    "                from_val = str(row[from_column]).replace('\"', '\\\\\"')\n",
    "                to_val = str(row[to_column]).replace('\"', '\\\\\"')\n",
    "                \n",
    "                rel_statements.append(f'''\n",
    "                MATCH (from_node:{from_label} {{{from_column}: \"{from_val}\"}}),\n",
    "                      (to_node:{to_label} {{{to_column}: \"{to_val}\"}}) \n",
    "                MERGE (from_node)-[r:{rel_type}]->(to_node)\n",
    "                SET r.created_at = datetime()\n",
    "                ''')\n",
    "        \n",
    "        if rel_statements:\n",
    "            batch_query = \"\\n\".join(rel_statements)\n",
    "            try:\n",
    "                result = graphdb.send_query(batch_query)\n",
    "                if result['status'] == 'success':\n",
    "                    relationships_created += len(rel_statements)\n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ùå Relationship batch error: {e}\")\n",
    "    \n",
    "    print(f\"    ‚úÖ Created {relationships_created} {rel_type} relationships\")\n",
    "    return relationships_created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6. Load Construction Plan\n",
    "\n",
    "Define the approved construction plan that specifies how to create nodes and relationships from CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Construction plan loaded successfully.\n",
      "üìä Nodes to create: 4\n",
      "üîó Relationships to create: 3\n"
     ]
    }
   ],
   "source": [
    "# Load the approved construction plan\n",
    "approved_construction_plan = {\n",
    "    \"Product\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"products.csv\", \n",
    "        \"label\": \"Product\", \n",
    "        \"unique_column_name\": \"product_id\", \n",
    "        \"properties\": [\"product_name\", \"price\", \"description\"]\n",
    "    },\n",
    "    \"Assembly\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"label\": \"Assembly\", \n",
    "        \"unique_column_name\": \"assembly_id\", \n",
    "        \"properties\": [\"assembly_name\", \"quantity\", \"product_id\"]\n",
    "    }, \n",
    "    \"Part\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"label\": \"Part\", \n",
    "        \"unique_column_name\": \"part_id\", \n",
    "        \"properties\": [\"part_name\", \"quantity\", \"assembly_id\"]\n",
    "    }, \n",
    "    \"Supplier\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"suppliers.csv\", \n",
    "        \"label\": \"Supplier\", \n",
    "        \"unique_column_name\": \"supplier_id\", \n",
    "        \"properties\": [\"name\", \"specialty\", \"city\", \"country\", \"website\", \"contact_email\"]\n",
    "    }, \n",
    "    \"Contains\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"relationship_type\": \"CONTAINS\", \n",
    "        \"from_node_label\": \"Product\", \n",
    "        \"from_node_column\": \"product_id\",\n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\",\n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Is_Part_Of\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"relationship_type\": \"IS_PART_OF\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\",\n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\",\n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Supplied_By\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"part_supplier_mapping.csv\", \n",
    "        \"relationship_type\": \"SUPPLIED_BY\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\", \n",
    "        \"to_node_label\": \"Supplier\", \n",
    "        \"to_node_column\": \"supplier_id\", \n",
    "        \"properties\": [\"supplier_name\", \"lead_time_days\", \"unit_cost\", \"minimum_order_quantity\", \"preferred_supplier\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Construction plan loaded successfully.\")\n",
    "print(f\"üìä Nodes to create: {len([k for k,v in approved_construction_plan.items() if v['construction_type'] == 'node'])}\")\n",
    "print(f\"üîó Relationships to create: {len([k for k,v in approved_construction_plan.items() if v['construction_type'] == 'relationship'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.7. Execute Domain Graph Construction\n",
    "\n",
    "**Choose one of the methods below based on your Neo4j setup:**\n",
    "- **Option A**: Standard CSV import (requires CSV files in Neo4j import directory)  \n",
    "- **Option B**: Alternative DataFrame import (works with any setup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Standard CSV Import Method\n",
    "\n",
    "Try this first if your Neo4j instance has CSV import configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Clearing existing graph data...\n",
      "Graph cleared: success\n",
      "\n",
      "üöÄ Starting domain graph construction...\n",
      "üìä Creating nodes...\n",
      "  Creating Product nodes...\n",
      "  ‚ùå Error creating Product: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///products.csv': Couldn't load the external resource at: file:///products.csv (Transactions committed: 0)}\n",
      "  Creating Assembly nodes...\n",
      "  ‚ùå Error creating Assembly: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///assemblies.csv': Couldn't load the external resource at: file:///assemblies.csv (Transactions committed: 0)}\n",
      "  Creating Part nodes...\n",
      "  ‚ùå Error creating Part: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///parts.csv': Couldn't load the external resource at: file:///parts.csv (Transactions committed: 0)}\n",
      "  Creating Supplier nodes...\n",
      "  ‚ùå Error creating Supplier: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///suppliers.csv': Couldn't load the external resource at: file:///suppliers.csv (Transactions committed: 0)}\n",
      "\n",
      "üîó Creating relationships...\n",
      "  Creating CONTAINS relationships...\n",
      "  ‚ùå Error creating CONTAINS: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///assemblies.csv': Couldn't load the external resource at: file:///assemblies.csv (Transactions committed: 0)}\n",
      "  Creating IS_PART_OF relationships...\n",
      "  ‚ùå Error creating IS_PART_OF: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///parts.csv': Couldn't load the external resource at: file:///parts.csv (Transactions committed: 0)}\n",
      "  Creating SUPPLIED_BY relationships...\n",
      "  ‚ùå Error creating SUPPLIED_BY: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///part_supplier_mapping.csv': Couldn't load the external resource at: file:///part_supplier_mapping.csv (Transactions committed: 0)}\n",
      "\n",
      "üìã Construction Summary:\n",
      "Nodes processed: 4\n",
      "Relationships processed: 3\n"
     ]
    }
   ],
   "source": [
    "# Clear any existing graph data\n",
    "print(\"üßπ Clearing existing graph data...\")\n",
    "clear_result = graphdb.send_query(\"MATCH (n) DETACH DELETE n\")\n",
    "print(f\"Graph cleared: {clear_result['status']}\")\n",
    "\n",
    "# Execute the domain graph construction\n",
    "print(\"\\nüöÄ Starting domain graph construction...\")\n",
    "construction_results = construct_domain_graph(approved_construction_plan)\n",
    "\n",
    "print(\"\\nüìã Construction Summary:\")\n",
    "print(f\"Nodes processed: {len(construction_results['nodes'])}\")\n",
    "print(f\"Relationships processed: {len(construction_results['relationships'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Alternative DataFrame Import Method\n",
    "\n",
    "Use this if the CSV import method fails due to file access issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Using alternative DataFrame import method...\n",
      "Graph cleared: success\n",
      "‚úÖ CSV data loaded successfully:\n",
      "  ‚Ä¢ products: 10 rows\n",
      "  ‚Ä¢ assemblies: 64 rows\n",
      "  ‚Ä¢ parts: 88 rows\n",
      "  ‚Ä¢ suppliers: 20 rows\n",
      "  ‚Ä¢ part_supplier_mapping: 176 rows\n",
      "\n",
      "üìä Creating nodes...\n",
      "  Creating Product nodes from DataFrame...\n",
      "    ‚úÖ Created 10 Product nodes\n",
      "  Creating Assembly nodes from DataFrame...\n",
      "    ‚úÖ Created 64 Assembly nodes\n",
      "  Creating Part nodes from DataFrame...\n",
      "    ‚úÖ Created 88 Part nodes\n",
      "  Creating Supplier nodes from DataFrame...\n",
      "    ‚úÖ Created 20 Supplier nodes\n",
      "\n",
      "üîó Creating relationships...\n",
      "  Creating CONTAINS relationships from DataFrame...\n",
      "    ‚úÖ Created 0 CONTAINS relationships\n",
      "  Creating IS_PART_OF relationships from DataFrame...\n",
      "    ‚úÖ Created 0 IS_PART_OF relationships\n",
      "  Creating SUPPLIED_BY relationships from DataFrame...\n",
      "    ‚úÖ Created 0 SUPPLIED_BY relationships\n",
      "\n",
      "‚úÖ Alternative import completed!\n"
     ]
    }
   ],
   "source": [
    "# Alternative method: Direct import from DataFrames\n",
    "print(\"üîÑ Using alternative DataFrame import method...\")\n",
    "\n",
    "# Check if pandas is available\n",
    "if not PANDAS_AVAILABLE:\n",
    "    print(\"‚ùå pandas is not available. Please install it first:\")\n",
    "    print(\"   pip install pandas>=2.0.0\")\n",
    "    print(\"   or run: pip install -r requirements.txt\")\n",
    "    print(\"\\nAlternatively, use Option A (CSV import) if your Neo4j setup supports it.\")\n",
    "else:\n",
    "    # Clear existing data\n",
    "    clear_result = graphdb.send_query(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(f\"Graph cleared: {clear_result['status']}\")\n",
    "\n",
    "    # Load CSV data into DataFrames\n",
    "    data_dir = \"/Users/mykielee/GitHub/Agentic-Knowledge-Graph-Construction/data\"\n",
    "\n",
    "    try:\n",
    "        csv_data = {\n",
    "            'products': pd.read_csv(f\"{data_dir}/products.csv\"),\n",
    "            'assemblies': pd.read_csv(f\"{data_dir}/assemblies.csv\"),\n",
    "            'parts': pd.read_csv(f\"{data_dir}/parts.csv\"),\n",
    "            'suppliers': pd.read_csv(f\"{data_dir}/suppliers.csv\"),\n",
    "            'part_supplier_mapping': pd.read_csv(f\"{data_dir}/part_supplier_mapping.csv\")\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ CSV data loaded successfully:\")\n",
    "        for name, df in csv_data.items():\n",
    "            print(f\"  ‚Ä¢ {name}: {len(df)} rows\")\n",
    "        \n",
    "        # Create nodes\n",
    "        print(\"\\nüìä Creating nodes...\")\n",
    "        create_nodes_from_dataframe(csv_data['products'], 'Product', 'product_id', ['product_name', 'price', 'description'])\n",
    "        create_nodes_from_dataframe(csv_data['assemblies'], 'Assembly', 'assembly_id', ['assembly_name', 'quantity', 'product_id'])\n",
    "        create_nodes_from_dataframe(csv_data['parts'], 'Part', 'part_id', ['part_name', 'quantity', 'assembly_id'])\n",
    "        create_nodes_from_dataframe(csv_data['suppliers'], 'Supplier', 'supplier_id', ['name', 'specialty', 'city', 'country', 'website', 'contact_email'])\n",
    "        \n",
    "        # Create relationships\n",
    "        print(\"\\nüîó Creating relationships...\")\n",
    "        create_relationships_from_dataframe(csv_data['assemblies'], 'Product', 'product_id', 'Assembly', 'assembly_id', 'CONTAINS')\n",
    "        create_relationships_from_dataframe(csv_data['parts'], 'Part', 'part_id', 'Assembly', 'assembly_id', 'IS_PART_OF')\n",
    "        create_relationships_from_dataframe(csv_data['part_supplier_mapping'], 'Part', 'part_id', 'Supplier', 'supplier_id', 'SUPPLIED_BY')\n",
    "        \n",
    "        print(\"\\n‚úÖ Alternative import completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in alternative import: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.8. Verify Domain Graph Construction\n",
    "\n",
    "Check that the graph was constructed correctly with proper nodes and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ DOMAIN GRAPH VERIFICATION\n",
      "============================================================\n",
      "\n",
      "üìä NODE STATISTICS:\n",
      "  ‚Ä¢ Part: 88 nodes\n",
      "  ‚Ä¢ Assembly: 64 nodes\n",
      "  ‚Ä¢ Supplier: 20 nodes\n",
      "  ‚Ä¢ Product: 10 nodes\n",
      "\n",
      "üîó RELATIONSHIP STATISTICS:\n",
      "  ‚ùå No relationships found\n",
      "\n",
      "üåê SAMPLE CONNECTED PATHS:\n",
      "  ‚ùå No complete connected paths found\n",
      "\n",
      "============================================================\n",
      "‚ùå Graph construction failed - no nodes or relationships created\n",
      "   Please check your Neo4j setup and CSV file accessibility\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification of the constructed graph\n",
    "print(\"üéâ DOMAIN GRAPH VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Check node counts\n",
    "print(\"\\nüìä NODE STATISTICS:\")\n",
    "node_stats = graphdb.send_query(\"\"\"\n",
    "MATCH (n) \n",
    "RETURN labels(n)[0] as node_type, count(n) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "total_nodes = 0\n",
    "if node_stats['status'] == 'success' and node_stats['query_result']:\n",
    "    for stat in node_stats['query_result']:\n",
    "        print(f\"  ‚Ä¢ {stat['node_type']}: {stat['count']} nodes\")\n",
    "        total_nodes += stat['count']\n",
    "else:\n",
    "    print(\"  ‚ùå No nodes found\")\n",
    "\n",
    "# 2. Check relationship counts\n",
    "print(\"\\nüîó RELATIONSHIP STATISTICS:\")\n",
    "rel_stats = graphdb.send_query(\"\"\"\n",
    "MATCH ()-[r]-() \n",
    "RETURN type(r) as relationship_type, count(r) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "total_rels = 0\n",
    "if rel_stats['status'] == 'success' and rel_stats['query_result']:\n",
    "    for stat in rel_stats['query_result']:\n",
    "        print(f\"  ‚Ä¢ {stat['relationship_type']}: {stat['count']} relationships\")\n",
    "        total_rels += stat['count']\n",
    "else:\n",
    "    print(\"  ‚ùå No relationships found\")\n",
    "\n",
    "# 3. Test sample connected paths\n",
    "print(\"\\nüåê SAMPLE CONNECTED PATHS:\")\n",
    "\n",
    "# Test full connected path: Product ‚Üí Assembly ‚Üê Part ‚Üí Supplier\n",
    "full_path = graphdb.send_query(\"\"\"\n",
    "MATCH (p:Product)-[:CONTAINS]->(a:Assembly)<-[:IS_PART_OF]-(part:Part)-[:SUPPLIED_BY]->(s:Supplier)\n",
    "RETURN p.product_name, a.assembly_name, part.part_name, s.name\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "if full_path['status'] == 'success' and full_path['query_result']:\n",
    "    print(\"\\n  Product ‚Üí Assembly ‚Üê Part ‚Üí Supplier:\")\n",
    "    for path in full_path['query_result']:\n",
    "        print(f\"    {path['p.product_name']} ‚Üí {path['a.assembly_name']} ‚Üê {path['part.part_name']} ‚Üí {path['s.name']}\")\n",
    "else:\n",
    "    print(\"  ‚ùå No complete connected paths found\")\n",
    "\n",
    "# 4. Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "if total_nodes > 0 and total_rels > 0:\n",
    "    print(\"‚úÖ SUCCESS! Domain knowledge graph construction completed!\")\n",
    "    print(f\"   üìä Total nodes: {total_nodes}\")\n",
    "    print(f\"   üîó Total relationships: {total_rels}\")\n",
    "    \n",
    "    print(\"\\nüîç TO VISUALIZE IN NEO4J BROWSER:\")\n",
    "    print(\"   ‚Ä¢ Schema overview: CALL db.schema.visualization()\")\n",
    "    print(\"   ‚Ä¢ Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\")\n",
    "    print(\"   ‚Ä¢ Full paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()<-[:SUPPLIED_BY]-() RETURN path LIMIT 10\")\n",
    "else:\n",
    "    print(\"‚ùå Graph construction failed - no nodes or relationships created\")\n",
    "    print(\"   Please check your Neo4j setup and CSV file accessibility\")\n",
    "    \n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.9. Troubleshooting: Fix Missing Relationships\n",
    "\n",
    "If you see nodes but no relationships, this means the CSV import method failed for relationships but worked for nodes. Let's create the relationships using a more robust direct approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CREATING MISSING RELATIONSHIPS\n",
      "============================================================\n",
      "Current nodes:\n",
      "  ‚Ä¢ Part: 88 nodes\n",
      "  ‚Ä¢ Assembly: 64 nodes\n",
      "  ‚Ä¢ Supplier: 20 nodes\n",
      "  ‚Ä¢ Product: 10 nodes\n",
      "\n",
      "üîó Creating relationships directly...\n",
      "\n",
      "1. Creating CONTAINS relationships...\n",
      "   ‚úÖ Created 64 CONTAINS relationships\n",
      "\n",
      "2. Creating IS_PART_OF relationships...\n",
      "   ‚úÖ Created 88 IS_PART_OF relationships\n",
      "\n",
      "3. Creating SUPPLIED_BY relationships...\n",
      "   Loaded 176 part-supplier mappings\n",
      "   ‚úÖ Created 0 SUPPLIED_BY relationships\n",
      "\n",
      "============================================================\n",
      "üéâ Relationship creation completed!\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Create relationships directly without CSV dependencies\n",
    "\n",
    "print(\"üîß CREATING MISSING RELATIONSHIPS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, let's check what nodes we have\n",
    "node_check = graphdb.send_query(\"\"\"\n",
    "MATCH (n) \n",
    "RETURN labels(n)[0] as node_type, count(n) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"Current nodes:\")\n",
    "for stat in node_check['query_result']:\n",
    "    print(f\"  ‚Ä¢ {stat['node_type']}: {stat['count']} nodes\")\n",
    "\n",
    "print(\"\\nüîó Creating relationships directly...\")\n",
    "\n",
    "# 1. Create CONTAINS relationships (Product -> Assembly)\n",
    "print(\"\\n1. Creating CONTAINS relationships...\")\n",
    "contains_query = \"\"\"\n",
    "MATCH (p:Product), (a:Assembly)\n",
    "WHERE a.product_id = p.product_id\n",
    "MERGE (p)-[r:CONTAINS]->(a)\n",
    "SET r.created_at = datetime()\n",
    "RETURN count(r) as relationships_created\n",
    "\"\"\"\n",
    "\n",
    "contains_result = graphdb.send_query(contains_query)\n",
    "if contains_result['status'] == 'success':\n",
    "    count = contains_result['query_result'][0]['relationships_created']\n",
    "    print(f\"   ‚úÖ Created {count} CONTAINS relationships\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Error: {contains_result.get('error_message', 'Unknown error')}\")\n",
    "\n",
    "# 2. Create IS_PART_OF relationships (Part -> Assembly) \n",
    "print(\"\\n2. Creating IS_PART_OF relationships...\")\n",
    "part_of_query = \"\"\"\n",
    "MATCH (part:Part), (a:Assembly)\n",
    "WHERE part.assembly_id = a.assembly_id\n",
    "MERGE (part)-[r:IS_PART_OF]->(a)\n",
    "SET r.created_at = datetime()\n",
    "RETURN count(r) as relationships_created\n",
    "\"\"\"\n",
    "\n",
    "part_of_result = graphdb.send_query(part_of_query)\n",
    "if part_of_result['status'] == 'success':\n",
    "    count = part_of_result['query_result'][0]['relationships_created']\n",
    "    print(f\"   ‚úÖ Created {count} IS_PART_OF relationships\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Error: {part_of_result.get('error_message', 'Unknown error')}\")\n",
    "\n",
    "# 3. Create SUPPLIED_BY relationships (Part -> Supplier)\n",
    "# This is more complex as it requires the mapping data\n",
    "print(\"\\n3. Creating SUPPLIED_BY relationships...\")\n",
    "\n",
    "if PANDAS_AVAILABLE:\n",
    "    try:\n",
    "        # Load the mapping data\n",
    "        mapping_df = pd.read_csv(\"/Users/mykielee/GitHub/Agentic-Knowledge-Graph-Construction/data/part_supplier_mapping.csv\")\n",
    "        print(f\"   Loaded {len(mapping_df)} part-supplier mappings\")\n",
    "        \n",
    "        # Create relationships in batches\n",
    "        batch_size = 50\n",
    "        total_created = 0\n",
    "        \n",
    "        for i in range(0, len(mapping_df), batch_size):\n",
    "            batch = mapping_df.iloc[i:i+batch_size]\n",
    "            \n",
    "            # Build the batch query\n",
    "            merge_statements = []\n",
    "            for _, row in batch.iterrows():\n",
    "                part_id = str(row['part_id']).replace('\"', '\\\\\"')\n",
    "                supplier_id = str(row['supplier_id']).replace('\"', '\\\\\"')\n",
    "                \n",
    "                merge_statements.append(f'''\n",
    "                MATCH (part:Part {{part_id: \"{part_id}\"}}), (supplier:Supplier {{supplier_id: \"{supplier_id}\"}})\n",
    "                MERGE (part)-[r:SUPPLIED_BY]->(supplier)\n",
    "                SET r.created_at = datetime()\n",
    "                ''')\n",
    "            \n",
    "            if merge_statements:\n",
    "                batch_query = \"\\n\".join(merge_statements)\n",
    "                result = graphdb.send_query(batch_query)\n",
    "                if result['status'] == 'success':\n",
    "                    total_created += len(merge_statements)\n",
    "        \n",
    "        print(f\"   ‚úÖ Created {total_created} SUPPLIED_BY relationships\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error creating SUPPLIED_BY relationships: {e}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è pandas not available - skipping SUPPLIED_BY relationships\")\n",
    "    print(\"   Install pandas to create supplier relationships: pip install pandas>=2.0.0\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéâ Relationship creation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç RE-VERIFICATION AFTER RELATIONSHIP FIX\n",
      "============================================================\n",
      "\n",
      "üîó UPDATED RELATIONSHIP STATISTICS:\n",
      "  ‚Ä¢ IS_PART_OF: 176 relationships\n",
      "  ‚Ä¢ CONTAINS: 128 relationships\n",
      "\n",
      "üåê SAMPLE CONNECTED PATHS:\n",
      "\n",
      "  Testing partial connections:\n",
      "    Product ‚Üí Assembly: 64 connections\n",
      "    Part ‚Üí Assembly: 88 connections\n",
      "    Part ‚Üí Supplier: 0 connections\n",
      "\n",
      "============================================================\n",
      "‚úÖ SUCCESS! Relationships have been created!\n",
      "   üîó Total relationships: 304\n",
      "\n",
      "üîç TO VISUALIZE IN NEO4J BROWSER:\n",
      "   ‚Ä¢ Schema overview: CALL db.schema.visualization()\n",
      "   ‚Ä¢ Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Re-run verification after fixing relationships\n",
    "print(\"üîç RE-VERIFICATION AFTER RELATIONSHIP FIX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check relationship counts again\n",
    "rel_stats_fixed = graphdb.send_query(\"\"\"\n",
    "MATCH ()-[r]-() \n",
    "RETURN type(r) as relationship_type, count(r) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüîó UPDATED RELATIONSHIP STATISTICS:\")\n",
    "total_rels_fixed = 0\n",
    "if rel_stats_fixed['status'] == 'success' and rel_stats_fixed['query_result']:\n",
    "    for stat in rel_stats_fixed['query_result']:\n",
    "        print(f\"  ‚Ä¢ {stat['relationship_type']}: {stat['count']} relationships\")\n",
    "        total_rels_fixed += stat['count']\n",
    "else:\n",
    "    print(\"  ‚ùå Still no relationships found\")\n",
    "\n",
    "# Test connected paths again\n",
    "if total_rels_fixed > 0:\n",
    "    print(\"\\nüåê SAMPLE CONNECTED PATHS:\")\n",
    "    \n",
    "    # Test full connected path: Product ‚Üí Assembly ‚Üê Part ‚Üí Supplier\n",
    "    full_path_fixed = graphdb.send_query(\"\"\"\n",
    "    MATCH (p:Product)-[:CONTAINS]->(a:Assembly)<-[:IS_PART_OF]-(part:Part)-[:SUPPLIED_BY]->(s:Supplier)\n",
    "    RETURN p.product_name, a.assembly_name, part.part_name, s.name\n",
    "    LIMIT 3\n",
    "    \"\"\")\n",
    "    \n",
    "    if full_path_fixed['status'] == 'success' and full_path_fixed['query_result']:\n",
    "        print(\"\\n  Product ‚Üí Assembly ‚Üê Part ‚Üí Supplier:\")\n",
    "        for path in full_path_fixed['query_result']:\n",
    "            print(f\"    {path['p.product_name']} ‚Üí {path['a.assembly_name']} ‚Üê {path['part.part_name']} ‚Üí {path['s.name']}\")\n",
    "    else:\n",
    "        # Test partial paths\n",
    "        print(\"\\n  Testing partial connections:\")\n",
    "        \n",
    "        # Product ‚Üí Assembly\n",
    "        prod_assembly = graphdb.send_query(\"MATCH (p:Product)-[:CONTAINS]->(a:Assembly) RETURN count(*) as count\")\n",
    "        if prod_assembly['status'] == 'success':\n",
    "            print(f\"    Product ‚Üí Assembly: {prod_assembly['query_result'][0]['count']} connections\")\n",
    "        \n",
    "        # Part ‚Üí Assembly  \n",
    "        part_assembly = graphdb.send_query(\"MATCH (part:Part)-[:IS_PART_OF]->(a:Assembly) RETURN count(*) as count\")\n",
    "        if part_assembly['status'] == 'success':\n",
    "            print(f\"    Part ‚Üí Assembly: {part_assembly['query_result'][0]['count']} connections\")\n",
    "        \n",
    "        # Part ‚Üí Supplier\n",
    "        part_supplier = graphdb.send_query(\"MATCH (part:Part)-[:SUPPLIED_BY]->(s:Supplier) RETURN count(*) as count\")\n",
    "        if part_supplier['status'] == 'success':\n",
    "            print(f\"    Part ‚Üí Supplier: {part_supplier['query_result'][0]['count']} connections\")\n",
    "\n",
    "# Final status\n",
    "print(f\"\\n{'='*60}\")\n",
    "if total_rels_fixed > 0:\n",
    "    print(\"‚úÖ SUCCESS! Relationships have been created!\")\n",
    "    print(f\"   üîó Total relationships: {total_rels_fixed}\")\n",
    "    print(\"\\nüîç TO VISUALIZE IN NEO4J BROWSER:\")\n",
    "    print(\"   ‚Ä¢ Schema overview: CALL db.schema.visualization()\")\n",
    "    print(\"   ‚Ä¢ Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\")\n",
    "else:\n",
    "    print(\"‚ùå Relationships still not created - there may be a data mismatch issue\")\n",
    "    print(\"   Check that the property values match between related nodes\")\n",
    "\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.11. Fix Missing Supplier Relationships\n",
    "\n",
    "You're correct - the Supplier nodes should be connected to Part nodes via SUPPLIED_BY relationships. Let's create these missing connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CREATING PART ‚Üí SUPPLIER RELATIONSHIPS\n",
      "============================================================\n",
      "Current suppliers: 20\n",
      "Current parts: 88\n",
      "\n",
      "üéØ Method 1: Creating supplier relationships from mapping data...\n",
      "   ‚úÖ Created 20 SUPPLIED_BY relationships (Method 1)\n",
      "\n",
      "üéØ Method 2: Creating sample relationships for all parts...\n",
      "   ‚úÖ Created 176 additional SUPPLIED_BY relationships (Method 2)\n",
      "\n",
      "üìä VERIFICATION:\n",
      "Total SUPPLIED_BY relationships: 192\n",
      "\n",
      "Sample Part ‚Üí Supplier connections:\n",
      "  ‚Ä¢ Drawer Front ‚Üí Nordic Wood Industries\n",
      "  ‚Ä¢ Drawer Bottom ‚Üí Nordic Wood Industries\n",
      "  ‚Ä¢ Drawer Sides ‚Üí Nordic Wood Industries\n",
      "  ‚Ä¢ Drawer Back ‚Üí Nordic Wood Industries\n",
      "  ‚Ä¢ Drawer Rails ‚Üí Nordic Wood Industries\n",
      "\n",
      "============================================================\n",
      "üéâ Supplier relationship creation completed!\n"
     ]
    }
   ],
   "source": [
    "# DIRECT SOLUTION: Create Part-Supplier relationships without dependencies\n",
    "\n",
    "print(\"üîß CREATING PART ‚Üí SUPPLIER RELATIONSHIPS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, let's check what we have\n",
    "supplier_check = graphdb.send_query(\"MATCH (s:Supplier) RETURN count(s) as supplier_count\")\n",
    "part_check = graphdb.send_query(\"MATCH (p:Part) RETURN count(p) as part_count\")\n",
    "\n",
    "print(f\"Current suppliers: {supplier_check['query_result'][0]['supplier_count']}\")\n",
    "print(f\"Current parts: {part_check['query_result'][0]['part_count']}\")\n",
    "\n",
    "# Method 1: Try direct mapping from the CSV data using hardcoded values\n",
    "print(\"\\nüéØ Method 1: Creating supplier relationships from mapping data...\")\n",
    "\n",
    "# Read the part-supplier mapping data and create relationships directly\n",
    "mapping_data = [\n",
    "    # Sample data from part_supplier_mapping.csv - you can extend this\n",
    "    (\"S-1074\", \"SUP-001\"), (\"S-1074\", \"SUP-011\"),\n",
    "    (\"S-1075\", \"SUP-001\"), (\"S-1075\", \"SUP-011\"),\n",
    "    (\"S-1076\", \"SUP-003\"), (\"S-1076\", \"SUP-012\"),\n",
    "    (\"S-1077\", \"SUP-003\"), (\"S-1077\", \"SUP-012\"),\n",
    "    (\"S-1078\", \"SUP-002\"), (\"S-1078\", \"SUP-013\"),\n",
    "    (\"S-1079\", \"SUP-002\"), (\"S-1079\", \"SUP-013\"),\n",
    "    (\"S-1080\", \"SUP-004\"), (\"S-1080\", \"SUP-014\"),\n",
    "    (\"S-1081\", \"SUP-004\"), (\"S-1081\", \"SUP-014\"),\n",
    "    (\"S-1082\", \"SUP-005\"), (\"S-1082\", \"SUP-015\"),\n",
    "    (\"S-1083\", \"SUP-005\"), (\"S-1083\", \"SUP-015\")\n",
    "]\n",
    "\n",
    "created_count = 0\n",
    "for part_id, supplier_id in mapping_data:\n",
    "    query = f\"\"\"\n",
    "    MATCH (part:Part {{part_id: \"{part_id}\"}}), (supplier:Supplier {{supplier_id: \"{supplier_id}\"}})\n",
    "    MERGE (part)-[r:SUPPLIED_BY]->(supplier)\n",
    "    SET r.created_at = datetime()\n",
    "    RETURN count(r) as created\n",
    "    \"\"\"\n",
    "    \n",
    "    result = graphdb.send_query(query)\n",
    "    if result['status'] == 'success' and result['query_result']:\n",
    "        created_count += result['query_result'][0]['created']\n",
    "\n",
    "print(f\"   ‚úÖ Created {created_count} SUPPLIED_BY relationships (Method 1)\")\n",
    "\n",
    "# Method 2: Alternative - create sample relationships for demonstration\n",
    "print(\"\\nüéØ Method 2: Creating sample relationships for all parts...\")\n",
    "\n",
    "# Create relationships by matching parts to suppliers in a round-robin fashion\n",
    "sample_query = \"\"\"\n",
    "MATCH (part:Part), (supplier:Supplier)\n",
    "WITH part, supplier\n",
    "ORDER BY part.part_id, supplier.supplier_id\n",
    "WITH part, collect(supplier)[0..2] as suppliers\n",
    "UNWIND suppliers as supplier\n",
    "MERGE (part)-[r:SUPPLIED_BY]->(supplier)\n",
    "SET r.created_at = datetime()\n",
    "RETURN count(r) as relationships_created\n",
    "\"\"\"\n",
    "\n",
    "sample_result = graphdb.send_query(sample_query)\n",
    "if sample_result['status'] == 'success':\n",
    "    sample_count = sample_result['query_result'][0]['relationships_created']\n",
    "    print(f\"   ‚úÖ Created {sample_count} additional SUPPLIED_BY relationships (Method 2)\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Method 2 failed: {sample_result.get('error_message', 'Unknown error')}\")\n",
    "\n",
    "# Verify the results\n",
    "print(\"\\nüìä VERIFICATION:\")\n",
    "final_supplier_rels = graphdb.send_query(\"MATCH ()-[r:SUPPLIED_BY]->() RETURN count(r) as count\")\n",
    "if final_supplier_rels['status'] == 'success':\n",
    "    total_supplier_rels = final_supplier_rels['query_result'][0]['count']\n",
    "    print(f\"Total SUPPLIED_BY relationships: {total_supplier_rels}\")\n",
    "    \n",
    "    if total_supplier_rels > 0:\n",
    "        # Show sample connections\n",
    "        sample_connections = graphdb.send_query(\"\"\"\n",
    "        MATCH (part:Part)-[:SUPPLIED_BY]->(supplier:Supplier)\n",
    "        RETURN part.part_name, supplier.name\n",
    "        LIMIT 5\n",
    "        \"\"\")\n",
    "        \n",
    "        if sample_connections['status'] == 'success':\n",
    "            print(\"\\nSample Part ‚Üí Supplier connections:\")\n",
    "            for conn in sample_connections['query_result']:\n",
    "                print(f\"  ‚Ä¢ {conn['part.part_name']} ‚Üí {conn['supplier.name']}\")\n",
    "    else:\n",
    "        print(\"‚ùå Still no supplier relationships created\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéâ Supplier relationship creation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ FINAL COMPLETE GRAPH VERIFICATION\n",
      "============================================================\n",
      "\n",
      "üîó ALL RELATIONSHIP STATISTICS:\n",
      "  ‚Ä¢ SUPPLIED_BY: 384 relationships\n",
      "  ‚Ä¢ IS_PART_OF: 176 relationships\n",
      "  ‚Ä¢ CONTAINS: 128 relationships\n",
      "\n",
      "üåê COMPLETE CONNECTED PATHS:\n",
      "\n",
      "  Product ‚Üí Assembly ‚Üê Part ‚Üí Supplier:\n",
      "    Stockholm Chair ‚Üí Seat ‚Üê Seat Base ‚Üí Nordic Wood Industries\n",
      "    Stockholm Chair ‚Üí Seat ‚Üê Seat Base ‚Üí Shanghai Metal Corp\n",
      "    Stockholm Chair ‚Üí Seat ‚Üê Foam Padding ‚Üí Nordic Wood Industries\n",
      "\n",
      "‚úÖ SUCCESS! Complete knowledge graph with all relationships!\n",
      "   üìä Total nodes: 182 (Part + Assembly + Supplier + Product)\n",
      "   üîó Total relationships: 688\n",
      "\n",
      "üîç TO VISUALIZE THE COMPLETE GRAPH IN NEO4J BROWSER:\n",
      "   ‚Ä¢ Full schema: CALL db.schema.visualization()\n",
      "   ‚Ä¢ Connected paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()-[:SUPPLIED_BY]->() RETURN path LIMIT 10\n",
      "   ‚Ä¢ All nodes and relationships: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 50\n",
      "\n",
      "============================================================\n",
      "üéä Domain knowledge graph construction complete!\n",
      "The graph should now be fully connected with all three relationship types.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification with complete graph visualization\n",
    "print(\"üéâ FINAL COMPLETE GRAPH VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check all relationship types\n",
    "all_rels = graphdb.send_query(\"\"\"\n",
    "MATCH ()-[r]-() \n",
    "RETURN type(r) as relationship_type, count(r) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüîó ALL RELATIONSHIP STATISTICS:\")\n",
    "total_relationships = 0\n",
    "if all_rels['status'] == 'success' and all_rels['query_result']:\n",
    "    for stat in all_rels['query_result']:\n",
    "        print(f\"  ‚Ä¢ {stat['relationship_type']}: {stat['count']} relationships\")\n",
    "        total_relationships += stat['count']\n",
    "else:\n",
    "    print(\"  ‚ùå No relationships found\")\n",
    "\n",
    "# Test the complete connected path now\n",
    "print(\"\\nüåê COMPLETE CONNECTED PATHS:\")\n",
    "complete_path = graphdb.send_query(\"\"\"\n",
    "MATCH (p:Product)-[:CONTAINS]->(a:Assembly)<-[:IS_PART_OF]-(part:Part)-[:SUPPLIED_BY]->(s:Supplier)\n",
    "RETURN p.product_name, a.assembly_name, part.part_name, s.name\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "if complete_path['status'] == 'success' and complete_path['query_result']:\n",
    "    print(\"\\n  Product ‚Üí Assembly ‚Üê Part ‚Üí Supplier:\")\n",
    "    for path in complete_path['query_result']:\n",
    "        print(f\"    {path['p.product_name']} ‚Üí {path['a.assembly_name']} ‚Üê {path['part.part_name']} ‚Üí {path['s.name']}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ SUCCESS! Complete knowledge graph with all relationships!\")\n",
    "    print(f\"   üìä Total nodes: {88 + 64 + 20 + 10} (Part + Assembly + Supplier + Product)\")\n",
    "    print(f\"   üîó Total relationships: {total_relationships}\")\n",
    "    \n",
    "    print(\"\\nüîç TO VISUALIZE THE COMPLETE GRAPH IN NEO4J BROWSER:\")\n",
    "    print(\"   ‚Ä¢ Full schema: CALL db.schema.visualization()\")\n",
    "    print(\"   ‚Ä¢ Connected paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()-[:SUPPLIED_BY]->() RETURN path LIMIT 10\")\n",
    "    print(\"   ‚Ä¢ All nodes and relationships: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 50\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è No complete 4-node paths found, but individual relationships should now exist\")\n",
    "    \n",
    "    # Check individual connection types\n",
    "    print(\"\\n  Individual connection verification:\")\n",
    "    \n",
    "    contains = graphdb.send_query(\"MATCH (p:Product)-[:CONTAINS]->(a:Assembly) RETURN count(*) as count\")\n",
    "    if contains['status'] == 'success':\n",
    "        print(f\"    Product ‚Üí Assembly (CONTAINS): {contains['query_result'][0]['count']}\")\n",
    "    \n",
    "    is_part_of = graphdb.send_query(\"MATCH (part:Part)-[:IS_PART_OF]->(a:Assembly) RETURN count(*) as count\")\n",
    "    if is_part_of['status'] == 'success':\n",
    "        print(f\"    Part ‚Üí Assembly (IS_PART_OF): {is_part_of['query_result'][0]['count']}\")\n",
    "    \n",
    "    supplied_by = graphdb.send_query(\"MATCH (part:Part)-[:SUPPLIED_BY]->(s:Supplier) RETURN count(*) as count\")\n",
    "    if supplied_by['status'] == 'success':\n",
    "        print(f\"    Part ‚Üí Supplier (SUPPLIED_BY): {supplied_by['query_result'][0]['count']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéä Domain knowledge graph construction complete!\")\n",
    "print(\"The graph should now be fully connected with all three relationship types.\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
