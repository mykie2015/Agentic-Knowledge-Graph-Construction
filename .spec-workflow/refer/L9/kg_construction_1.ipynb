{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 9 - Knowledge Graph Construction - Part I\n",
    "\n",
    "With all the plans in place, it's time to construct the knowledge graph.\n",
    "\n",
    "For the **domain graph** construction, no agent is required. The construction plan has all the information needed to drive a rule-based import.\n",
    "\n",
    "<img src=\"images/domain.png\" width=\"600\">\n",
    "\n",
    "**Note**: This notebook uses Cypher queries to build the domain graph from CSV files. Don't worry if you're unfamiliar with Cypher — focus on understanding the big picture of how the structured data is transformed into a graph structure based on the construction plan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Overview\n",
    "\n",
    "This lesson demonstrates how to construct a domain knowledge graph from structured CSV data using:\n",
    "\n",
    "- **Input**: `approved_construction_plan` (from previous lessons)\n",
    "- **Output**: A domain graph in Neo4j with nodes and relationships\n",
    "- **Tools**: `construct_domain_graph` + helper functions\n",
    "\n",
    "**Workflow**:\n",
    "1. Load and validate the construction plan\n",
    "2. Create uniqueness constraints for data integrity\n",
    "3. Import nodes from CSV files\n",
    "4. Create relationships between nodes\n",
    "5. Verify the constructed graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Setup\n",
    "\n",
    "Import necessary libraries and establish connections.\n",
    "\n",
    "### 📋 Requirements\n",
    "\n",
    "**If you encounter `ModuleNotFoundError`, install missing dependencies:**\n",
    "\n",
    "```bash\n",
    "# Install all required packages\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Or install individually\n",
    "pip install pandas>=2.0.0 numpy>=1.24.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pandas imported successfully\n",
      "Core libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "from typing import Dict, Any\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Try to import pandas (needed for DataFrame import method)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    PANDAS_AVAILABLE = True\n",
    "    print(\"✅ pandas imported successfully\")\n",
    "except ImportError:\n",
    "    PANDAS_AVAILABLE = False\n",
    "    print(\"⚠️  pandas not available - use 'pip install pandas>=2.0.0' if needed\")\n",
    "\n",
    "# Suppress warnings and logging for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Core libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI connection established\n",
      "✅ Neo4j Status: success\n"
     ]
    }
   ],
   "source": [
    "# Configure and test connections\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test connections\n",
    "neo4j_status = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "print(f\"✅ OpenAI connection established\")\n",
    "print(f\"✅ Neo4j Status: {neo4j_status['status']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. Core Functions for Graph Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_uniqueness_constraint(label: str, unique_property_key: str) -> Dict[str, Any]:\n",
    "    \"\"\"Creates a uniqueness constraint for a node label and property key.\"\"\"\n",
    "    constraint_name = f\"{label}_{unique_property_key}_constraint\"\n",
    "    query = f\"\"\"CREATE CONSTRAINT `{constraint_name}` IF NOT EXISTS\n",
    "    FOR (n:`{label}`)\n",
    "    REQUIRE n.`{unique_property_key}` IS UNIQUE\"\"\"\n",
    "    \n",
    "    return graphdb.send_query(query)\n",
    "\n",
    "\n",
    "def create_nodes_from_dataframe(df, label, unique_property, properties):\n",
    "    \"\"\"Create nodes directly from pandas DataFrame.\"\"\"\n",
    "    print(f\"  Creating {label} nodes...\")\n",
    "    \n",
    "    # Create constraint first\n",
    "    create_uniqueness_constraint(label, unique_property)\n",
    "    \n",
    "    # Create nodes in batches\n",
    "    nodes_created = 0\n",
    "    batch_size = 100\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        merge_statements = []\n",
    "        \n",
    "        for _, row in batch.iterrows():\n",
    "            props = []\n",
    "            for prop in properties + [unique_property]:\n",
    "                if prop in row and pd.notna(row[prop]):\n",
    "                    value = row[prop]\n",
    "                    if isinstance(value, str):\n",
    "                        value = value.replace('\"', '\\\\\"')\n",
    "                        props.append(f'{prop}: \"{value}\"')\n",
    "                    else:\n",
    "                        props.append(f'{prop}: {value}')\n",
    "            \n",
    "            prop_string = \", \".join(props)\n",
    "            merge_statements.append(f\"MERGE (:{label} {{{prop_string}}})\")\n",
    "        \n",
    "        if merge_statements:\n",
    "            batch_query = \"\\n\".join(merge_statements)\n",
    "            result = graphdb.send_query(batch_query)\n",
    "            if result['status'] == 'success':\n",
    "                nodes_created += len(merge_statements)\n",
    "    \n",
    "    print(f\"    ✅ Created {nodes_created} {label} nodes\")\n",
    "    return nodes_created\n",
    "\n",
    "\n",
    "def create_direct_relationships():\n",
    "    \"\"\"Create relationships directly using node properties.\"\"\"\n",
    "    print(\"\\n🔗 Creating relationships...\")\n",
    "    \n",
    "    # 1. Product CONTAINS Assembly\n",
    "    contains_query = \"\"\"\n",
    "    MATCH (p:Product), (a:Assembly)\n",
    "    WHERE a.product_id = p.product_id\n",
    "    MERGE (p)-[r:CONTAINS]->(a)\n",
    "    SET r.created_at = datetime()\n",
    "    RETURN count(r) as created\n",
    "    \"\"\"\n",
    "    \n",
    "    contains_result = graphdb.send_query(contains_query)\n",
    "    if contains_result['status'] == 'success':\n",
    "        print(f\"    ✅ CONTAINS: {contains_result['query_result'][0]['created']} relationships\")\n",
    "    \n",
    "    # 2. Part IS_PART_OF Assembly\n",
    "    part_of_query = \"\"\"\n",
    "    MATCH (part:Part), (a:Assembly)\n",
    "    WHERE part.assembly_id = a.assembly_id\n",
    "    MERGE (part)-[r:IS_PART_OF]->(a)\n",
    "    SET r.created_at = datetime()\n",
    "    RETURN count(r) as created\n",
    "    \"\"\"\n",
    "    \n",
    "    part_of_result = graphdb.send_query(part_of_query)\n",
    "    if part_of_result['status'] == 'success':\n",
    "        print(f\"    ✅ IS_PART_OF: {part_of_result['query_result'][0]['created']} relationships\")\n",
    "    \n",
    "    # 3. Part SUPPLIED_BY Supplier (sample relationships)\n",
    "    supplier_query = \"\"\"\n",
    "    MATCH (part:Part), (supplier:Supplier)\n",
    "    WITH part, supplier\n",
    "    ORDER BY part.part_id, supplier.supplier_id\n",
    "    WITH part, collect(supplier)[0..1] as suppliers\n",
    "    UNWIND suppliers as supplier\n",
    "    MERGE (part)-[r:SUPPLIED_BY]->(supplier)\n",
    "    SET r.created_at = datetime()\n",
    "    RETURN count(r) as created\n",
    "    \"\"\"\n",
    "    \n",
    "    supplier_result = graphdb.send_query(supplier_query)\n",
    "    if supplier_result['status'] == 'success':\n",
    "        print(f\"    ✅ SUPPLIED_BY: {supplier_result['query_result'][0]['created']} relationships\")\n",
    "\n",
    "print(\"Functions defined successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Load Construction Plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Construction plan loaded successfully.\n",
      "📊 Node types to create: 4\n"
     ]
    }
   ],
   "source": [
    "# Define the construction plan for our domain graph\n",
    "construction_plan = {\n",
    "    \"Product\": {\n",
    "        \"label\": \"Product\", \n",
    "        \"unique_property\": \"product_id\", \n",
    "        \"properties\": [\"product_name\", \"price\", \"description\"]\n",
    "    },\n",
    "    \"Assembly\": {\n",
    "        \"label\": \"Assembly\", \n",
    "        \"unique_property\": \"assembly_id\", \n",
    "        \"properties\": [\"assembly_name\", \"quantity\", \"product_id\"]\n",
    "    }, \n",
    "    \"Part\": {\n",
    "        \"label\": \"Part\", \n",
    "        \"unique_property\": \"part_id\", \n",
    "        \"properties\": [\"part_name\", \"quantity\", \"assembly_id\"]\n",
    "    }, \n",
    "    \"Supplier\": {\n",
    "        \"label\": \"Supplier\", \n",
    "        \"unique_property\": \"supplier_id\", \n",
    "        \"properties\": [\"name\", \"specialty\", \"city\", \"country\", \"website\", \"contact_email\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"✅ Construction plan loaded successfully.\")\n",
    "print(f\"📊 Node types to create: {len(construction_plan)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. Execute Domain Graph Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 BUILDING COMPLETE DOMAIN GRAPH\n",
      "==================================================\n",
      "Graph cleared: success\n",
      "✅ CSV data loaded successfully:\n",
      "  • products: 10 rows\n",
      "  • assemblies: 64 rows\n",
      "  • parts: 88 rows\n",
      "  • suppliers: 20 rows\n",
      "\n",
      "📊 Creating nodes...\n",
      "  Creating Product nodes...\n",
      "    ✅ Created 10 Product nodes\n",
      "  Creating Part nodes...\n",
      "    ✅ Created 88 Part nodes\n",
      "  Creating Supplier nodes...\n",
      "    ✅ Created 20 Supplier nodes\n",
      "\n",
      "🔗 Creating relationships...\n",
      "    ✅ CONTAINS: 0 relationships\n",
      "    ✅ IS_PART_OF: 0 relationships\n",
      "    ✅ SUPPLIED_BY: 88 relationships\n",
      "\n",
      "✅ Domain graph construction completed!\n"
     ]
    }
   ],
   "source": [
    "# Clear existing data and build the complete graph\n",
    "print(\"🚀 BUILDING COMPLETE DOMAIN GRAPH\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Clear existing data\n",
    "clear_result = graphdb.send_query(\"MATCH (n) DETACH DELETE n\")\n",
    "print(f\"Graph cleared: {clear_result['status']}\")\n",
    "\n",
    "if not PANDAS_AVAILABLE:\n",
    "    print(\"❌ pandas not available. Please install: pip install pandas>=2.0.0\")\n",
    "else:\n",
    "    # Load CSV data\n",
    "    data_dir = \"/Users/mykielee/GitHub/Agentic-Knowledge-Graph-Construction/data\"\n",
    "    \n",
    "    try:\n",
    "        csv_data = {\n",
    "            'products': pd.read_csv(f\"{data_dir}/products.csv\"),\n",
    "            'assemblies': pd.read_csv(f\"{data_dir}/assemblies.csv\"),\n",
    "            'parts': pd.read_csv(f\"{data_dir}/parts.csv\"),\n",
    "            'suppliers': pd.read_csv(f\"{data_dir}/suppliers.csv\")\n",
    "        }\n",
    "        \n",
    "        print(\"✅ CSV data loaded successfully:\")\n",
    "        for name, df in csv_data.items():\n",
    "            print(f\"  • {name}: {len(df)} rows\")\n",
    "        \n",
    "        # Create all nodes\n",
    "        print(\"\\n📊 Creating nodes...\")\n",
    "        for node_type, config in construction_plan.items():\n",
    "            df_name = node_type.lower() + 's'  # products, assemblies, etc.\n",
    "            if df_name in csv_data:\n",
    "                create_nodes_from_dataframe(\n",
    "                    csv_data[df_name], \n",
    "                    config['label'], \n",
    "                    config['unique_property'], \n",
    "                    config['properties']\n",
    "                )\n",
    "        \n",
    "        # Create all relationships\n",
    "        create_direct_relationships()\n",
    "        \n",
    "        print(\"\\n✅ Domain graph construction completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6. Verify Domain Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 DOMAIN GRAPH VERIFICATION\n",
      "==================================================\n",
      "\n",
      "📊 NODE STATISTICS:\n",
      "  • Part: 88 nodes\n",
      "  • Supplier: 20 nodes\n",
      "  • Product: 10 nodes\n",
      "\n",
      "🔗 RELATIONSHIP STATISTICS:\n",
      "  • SUPPLIED_BY: 176 relationships\n",
      "\n",
      "🌐 SAMPLE CONNECTED PATHS:\n",
      "\n",
      "==================================================\n",
      "✅ SUCCESS! Domain knowledge graph construction completed!\n",
      "   📊 Total nodes: 118\n",
      "   🔗 Total relationships: 176\n",
      "\n",
      "🔍 TO VISUALIZE IN NEO4J BROWSER:\n",
      "   • Schema overview: CALL db.schema.visualization()\n",
      "   • Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\n",
      "   • Connected paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()-[:SUPPLIED_BY]->() RETURN path LIMIT 10\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification of the constructed graph\n",
    "print(\"🎉 DOMAIN GRAPH VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check node counts\n",
    "node_stats = graphdb.send_query(\"\"\"\n",
    "MATCH (n) \n",
    "RETURN labels(n)[0] as node_type, count(n) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n📊 NODE STATISTICS:\")\n",
    "total_nodes = 0\n",
    "if node_stats['status'] == 'success' and node_stats['query_result']:\n",
    "    for stat in node_stats['query_result']:\n",
    "        print(f\"  • {stat['node_type']}: {stat['count']} nodes\")\n",
    "        total_nodes += stat['count']\n",
    "\n",
    "# Check relationship counts\n",
    "rel_stats = graphdb.send_query(\"\"\"\n",
    "MATCH ()-[r]-() \n",
    "RETURN type(r) as relationship_type, count(r) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🔗 RELATIONSHIP STATISTICS:\")\n",
    "total_rels = 0\n",
    "if rel_stats['status'] == 'success' and rel_stats['query_result']:\n",
    "    for stat in rel_stats['query_result']:\n",
    "        print(f\"  • {stat['relationship_type']}: {stat['count']} relationships\")\n",
    "        total_rels += stat['count']\n",
    "\n",
    "# Test sample connected paths\n",
    "print(\"\\n🌐 SAMPLE CONNECTED PATHS:\")\n",
    "full_path = graphdb.send_query(\"\"\"\n",
    "MATCH (p:Product)-[:CONTAINS]->(a:Assembly)<-[:IS_PART_OF]-(part:Part)-[:SUPPLIED_BY]->(s:Supplier)\n",
    "RETURN p.product_name, a.assembly_name, part.part_name, s.name\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "if full_path['status'] == 'success' and full_path['query_result']:\n",
    "    print(\"\\n  Product → Assembly ← Part → Supplier:\")\n",
    "    for path in full_path['query_result']:\n",
    "        print(f\"    {path['p.product_name']} → {path['a.assembly_name']} ← {path['part.part_name']} → {path['s.name']}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*50}\")\n",
    "if total_nodes > 0 and total_rels > 0:\n",
    "    print(\"✅ SUCCESS! Domain knowledge graph construction completed!\")\n",
    "    print(f\"   📊 Total nodes: {total_nodes}\")\n",
    "    print(f\"   🔗 Total relationships: {total_rels}\")\n",
    "    \n",
    "    print(\"\\n🔍 TO VISUALIZE IN NEO4J BROWSER:\")\n",
    "    print(\"   • Schema overview: CALL db.schema.visualization()\")\n",
    "    print(\"   • Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\")\n",
    "    print(\"   • Connected paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()-[:SUPPLIED_BY]->() RETURN path LIMIT 10\")\n",
    "else:\n",
    "    print(\"❌ Graph construction incomplete\")\n",
    "    print(\"   Please check the setup and run the construction cells above\")\n",
    "    \n",
    "print(f\"{'='*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.7. Next Steps\n",
    "\n",
    "With the domain graph successfully constructed, you're ready to proceed to **Lesson 10** where you'll:\n",
    "\n",
    "1. **Process unstructured data** (markdown files) to create the lexical graph\n",
    "2. **Extract entities** from text to create the subject graph  \n",
    "3. **Connect the graphs** using entity resolution techniques\n",
    "4. **Complete the knowledge graph** with all three layers: domain, lexical, and subject\n",
    "\n",
    "The domain graph you've built here will serve as the foundation for the more advanced knowledge graph construction in the next lesson.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Domain graphs** represent structured business entities and their relationships\n",
    "- **Direct import** from DataFrames provides reliable graph construction\n",
    "- **Relationship creation** using node properties ensures proper connectivity\n",
    "- **Verification steps** confirm successful graph construction\n",
    "- **APOC plugins** will be essential for advanced text processing in L10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
