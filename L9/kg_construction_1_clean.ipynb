{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 9 - Knowledge Graph Construction - Part I\n",
    "\n",
    "With all the plans in place, it's time to construct the knowledge graph.\n",
    "\n",
    "For the **domain graph** construction, no agent is required. The construction plan has all the information needed to drive a rule-based import.\n",
    "\n",
    "<img src=\"images/domain.png\" width=\"600\">\n",
    "\n",
    "**Note**: This notebook uses Cypher queries to build the domain graph from CSV files. Don't worry if you're unfamiliar with Cypher — focus on understanding the big picture of how the structured data is transformed into a graph structure based on the construction plan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Overview\n",
    "\n",
    "This lesson demonstrates how to construct a domain knowledge graph from structured CSV data using:\n",
    "\n",
    "- **Input**: `approved_construction_plan` (from previous lessons)\n",
    "- **Output**: A domain graph in Neo4j with nodes and relationships\n",
    "- **Tools**: `construct_domain_graph` + helper functions\n",
    "\n",
    "**Workflow**:\n",
    "1. Load and validate the construction plan\n",
    "2. Create uniqueness constraints for data integrity\n",
    "3. Import nodes from CSV files\n",
    "4. Create relationships between nodes\n",
    "5. Verify the constructed graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Setup\n",
    "\n",
    "Import necessary libraries, load environment variables, and establish connection to Neo4j.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📋 Quick Setup Instructions\n",
    "\n",
    "**If you encounter `ModuleNotFoundError`, install missing dependencies:**\n",
    "\n",
    "```bash\n",
    "# Install all required packages\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Or install individually\n",
    "pip install pandas>=2.0.0 numpy>=1.24.0\n",
    "```\n",
    "\n",
    "**Note**: pandas is only required for Option B (DataFrame import). Option A (CSV import) works without pandas if your Neo4j instance supports CSV loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pandas imported successfully\n",
      "Core libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "from typing import Dict, Any\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Try to import pandas (needed only for Option B - DataFrame import)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    PANDAS_AVAILABLE = True\n",
    "    print(\"✅ pandas imported successfully\")\n",
    "except ImportError:\n",
    "    PANDAS_AVAILABLE = False\n",
    "    print(\"⚠️  pandas not available - Option B (DataFrame import) will not work\")\n",
    "    print(\"   Install with: pip install pandas>=2.0.0\")\n",
    "    print(\"   You can still use Option A (CSV import) if Neo4j import is configured\")\n",
    "\n",
    "# Suppress warnings and logging for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Core libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI connection established.\n"
     ]
    }
   ],
   "source": [
    "# Configure the language model\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM connection\n",
    "test_response = llm.llm_client.completion(\n",
    "    model=llm.model, \n",
    "    messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], \n",
    "    tools=[]\n",
    ")\n",
    "print(\"✅ OpenAI connection established.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j Status: {'status': 'success', 'query_result': [{'message': 'Neo4j is Ready!'}]}\n",
      "✅ Neo4j connection established successfully.\n"
     ]
    }
   ],
   "source": [
    "# Test Neo4j connection\n",
    "neo4j_status = graphdb.send_query(\"RETURN 'Neo4j is Ready!' as message\")\n",
    "print(f\"Neo4j Status: {neo4j_status}\")\n",
    "\n",
    "if neo4j_status['status'] == 'success':\n",
    "    print(\"✅ Neo4j connection established successfully.\")\n",
    "else:\n",
    "    print(\"❌ Neo4j connection failed. Please check your configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. Neo4j Plugin Verification\n",
    "\n",
    "Check that required Neo4j plugins (especially APOC) are installed and available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CHECKING NEO4J PLUGINS\n",
      "==================================================\n",
      "✅ APOC is installed - Version: 2025.08.0\n",
      "✅ APOC text functions are available\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Check Neo4j components and plugins\n",
    "print(\"🔍 CHECKING NEO4J PLUGINS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check APOC availability (needed for advanced text functions in later lessons)\n",
    "try:\n",
    "    apoc_check = graphdb.send_query(\"RETURN apoc.version() AS apoc_version\")\n",
    "    if apoc_check['status'] == 'success' and apoc_check['query_result']:\n",
    "        apoc_version = apoc_check['query_result'][0]['apoc_version']\n",
    "        print(f\"✅ APOC is installed - Version: {apoc_version}\")\n",
    "        \n",
    "        # Test APOC text functions (needed for entity resolution in L10)\n",
    "        text_func_test = graphdb.send_query(\"RETURN apoc.text.jaroWinklerDistance('test', 'test') AS similarity\")\n",
    "        if text_func_test['status'] == 'success':\n",
    "            print(\"✅ APOC text functions are available\")\n",
    "        else:\n",
    "            print(\"⚠️  APOC text functions may not be available\")\n",
    "    else:\n",
    "        print(\"⚠️  APOC is not installed (will be needed for L10)\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  APOC is not installed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Core Functions for Domain Graph Construction\n",
    "\n",
    "These functions handle the creation of nodes and relationships from CSV data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniqueness_constraint(label: str, unique_property_key: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Creates a uniqueness constraint for a node label and property key.\n",
    "    \n",
    "    Args:\n",
    "        label: The label of the node to create a constraint for.\n",
    "        unique_property_key: The property key that should have a unique value.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with a status key ('success' or 'error').\n",
    "    \"\"\"\n",
    "    constraint_name = f\"{label}_{unique_property_key}_constraint\"\n",
    "    query = f\"\"\"CREATE CONSTRAINT `{constraint_name}` IF NOT EXISTS\n",
    "    FOR (n:`{label}`)\n",
    "    REQUIRE n.`{unique_property_key}` IS UNIQUE\"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = graphdb.send_query(query)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_nodes(node_construction: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Import nodes as defined by a node construction rule.\n",
    "    \n",
    "    Args:\n",
    "        node_construction: Dictionary containing node import configuration\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and any error messages\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First create the uniqueness constraint\n",
    "        constraint_result = create_uniqueness_constraint(\n",
    "            node_construction[\"label\"], \n",
    "            node_construction[\"unique_column_name\"]\n",
    "        )\n",
    "        \n",
    "        if constraint_result[\"status\"] == \"error\":\n",
    "            return constraint_result\n",
    "\n",
    "        # Then load nodes from CSV - simplified version without APOC dependency\n",
    "        properties = node_construction[\"properties\"]\n",
    "        unique_column = node_construction[\"unique_column_name\"]\n",
    "        label = node_construction[\"label\"]\n",
    "        \n",
    "        # Build SET clause for properties\n",
    "        set_clauses = [f\"n.{prop} = row.{prop}\" for prop in properties]\n",
    "        set_clause = \", \".join(set_clauses)\n",
    "        \n",
    "        query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "        CALL {{\n",
    "            WITH row\n",
    "            MERGE (n:{label} {{ {unique_column} : row.{unique_column} }})\n",
    "            SET {set_clause}\n",
    "        }} IN TRANSACTIONS OF 1000 ROWS\n",
    "        \"\"\"\n",
    "        \n",
    "        results = graphdb.send_query(query, {\n",
    "            \"source_file\": node_construction[\"source_file\"]\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_relationships(relationship_construction: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Import relationships as defined by a relationship construction rule.\n",
    "    \n",
    "    Args:\n",
    "        relationship_construction: Dictionary containing relationship configuration\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with status and any error messages\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from_node_column = relationship_construction[\"from_node_column\"]\n",
    "        to_node_column = relationship_construction[\"to_node_column\"]\n",
    "        from_label = relationship_construction[\"from_node_label\"]\n",
    "        to_label = relationship_construction[\"to_node_label\"]\n",
    "        rel_type = relationship_construction[\"relationship_type\"]\n",
    "        \n",
    "        query = f\"\"\"LOAD CSV WITH HEADERS FROM \"file:///\" + $source_file AS row\n",
    "        CALL {{\n",
    "            WITH row\n",
    "            MATCH (from_node:{from_label} {{ {from_node_column} : row.{from_node_column} }}),\n",
    "                  (to_node:{to_label} {{ {to_node_column} : row.{to_node_column} }})\n",
    "            MERGE (from_node)-[r:{rel_type}]->(to_node)\n",
    "            SET r.created_at = datetime()\n",
    "        }} IN TRANSACTIONS OF 1000 ROWS\n",
    "        \"\"\"\n",
    "        \n",
    "        results = graphdb.send_query(query, {\n",
    "            \"source_file\": relationship_construction[\"source_file\"]\n",
    "        })\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"status\": \"error\", \"error_message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_domain_graph(construction_plan: dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Construct a domain graph according to a construction plan.\n",
    "    \n",
    "    Args:\n",
    "        construction_plan: Dictionary containing both node and relationship rules\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with construction results\n",
    "    \"\"\"\n",
    "    results = {\"nodes\": [], \"relationships\": []}\n",
    "    \n",
    "    # First, import nodes\n",
    "    print(\"📊 Creating nodes...\")\n",
    "    node_constructions = [value for value in construction_plan.values() \n",
    "                         if value['construction_type'] == 'node']\n",
    "    \n",
    "    for node_construction in node_constructions:\n",
    "        label = node_construction['label']\n",
    "        print(f\"  Creating {label} nodes...\")\n",
    "        result = import_nodes(node_construction)\n",
    "        results[\"nodes\"].append({\"label\": label, \"result\": result})\n",
    "        \n",
    "        if result[\"status\"] == \"error\":\n",
    "            print(f\"  ❌ Error creating {label}: {result['error_message']}\")\n",
    "        else:\n",
    "            print(f\"  ✅ {label} nodes created successfully\")\n",
    "\n",
    "    # Second, import relationships\n",
    "    print(\"\\n🔗 Creating relationships...\")\n",
    "    relationship_constructions = [value for value in construction_plan.values() \n",
    "                                 if value['construction_type'] == 'relationship']\n",
    "    \n",
    "    for relationship_construction in relationship_constructions:\n",
    "        rel_type = relationship_construction['relationship_type']\n",
    "        print(f\"  Creating {rel_type} relationships...\")\n",
    "        result = import_relationships(relationship_construction)\n",
    "        results[\"relationships\"].append({\"type\": rel_type, \"result\": result})\n",
    "        \n",
    "        if result[\"status\"] == \"error\":\n",
    "            print(f\"  ❌ Error creating {rel_type}: {result['error_message']}\")\n",
    "        else:\n",
    "            print(f\"  ✅ {rel_type} relationships created successfully\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. Alternative: Direct Data Import Functions\n",
    "\n",
    "If Neo4j CSV import is not available, these functions provide an alternative approach using pandas DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nodes_from_dataframe(df, label, unique_property, properties):\n",
    "    \"\"\"\n",
    "    Create nodes directly from pandas DataFrame (alternative to CSV import).\n",
    "    \"\"\"\n",
    "    print(f\"  Creating {label} nodes from DataFrame...\")\n",
    "    \n",
    "    # Create constraint first\n",
    "    constraint_query = f\"CREATE CONSTRAINT IF NOT EXISTS FOR (n:{label}) REQUIRE n.{unique_property} IS UNIQUE\"\n",
    "    constraint_result = graphdb.send_query(constraint_query)\n",
    "    \n",
    "    # Create nodes in batches\n",
    "    nodes_created = 0\n",
    "    batch_size = 100\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Build MERGE statements for this batch\n",
    "        merge_statements = []\n",
    "        for _, row in batch.iterrows():\n",
    "            # Build property string\n",
    "            props = []\n",
    "            for prop in properties + [unique_property]:\n",
    "                if prop in row and pd.notna(row[prop]):\n",
    "                    value = row[prop]\n",
    "                    if isinstance(value, str):\n",
    "                        value = value.replace('\"', '\\\\\"')\n",
    "                        props.append(f'{prop}: \"{value}\"')\n",
    "                    else:\n",
    "                        props.append(f'{prop}: {value}')\n",
    "            \n",
    "            prop_string = \", \".join(props)\n",
    "            merge_statements.append(f\"MERGE (:{label} {{{prop_string}}})\")\n",
    "        \n",
    "        # Execute batch\n",
    "        if merge_statements:\n",
    "            batch_query = \"\\n\".join(merge_statements)\n",
    "            try:\n",
    "                result = graphdb.send_query(batch_query)\n",
    "                if result['status'] == 'success':\n",
    "                    nodes_created += len(merge_statements)\n",
    "            except Exception as e:\n",
    "                print(f\"    ❌ Batch error: {e}\")\n",
    "    \n",
    "    print(f\"    ✅ Created {nodes_created} {label} nodes\")\n",
    "    return nodes_created\n",
    "\n",
    "\n",
    "def create_relationships_from_dataframe(df, from_label, from_column, to_label, to_column, rel_type):\n",
    "    \"\"\"\n",
    "    Create relationships directly from pandas DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"  Creating {rel_type} relationships from DataFrame...\")\n",
    "    \n",
    "    relationships_created = 0\n",
    "    batch_size = 50\n",
    "    \n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        rel_statements = []\n",
    "        for _, row in batch.iterrows():\n",
    "            if pd.notna(row[from_column]) and pd.notna(row[to_column]):\n",
    "                from_val = str(row[from_column]).replace('\"', '\\\\\"')\n",
    "                to_val = str(row[to_column]).replace('\"', '\\\\\"')\n",
    "                \n",
    "                rel_statements.append(f'''\n",
    "                MATCH (from_node:{from_label} {{{from_column}: \"{from_val}\"}}),\n",
    "                      (to_node:{to_label} {{{to_column}: \"{to_val}\"}}) \n",
    "                MERGE (from_node)-[r:{rel_type}]->(to_node)\n",
    "                SET r.created_at = datetime()\n",
    "                ''')\n",
    "        \n",
    "        if rel_statements:\n",
    "            batch_query = \"\\n\".join(rel_statements)\n",
    "            try:\n",
    "                result = graphdb.send_query(batch_query)\n",
    "                if result['status'] == 'success':\n",
    "                    relationships_created += len(rel_statements)\n",
    "            except Exception as e:\n",
    "                print(f\"    ❌ Relationship batch error: {e}\")\n",
    "    \n",
    "    print(f\"    ✅ Created {relationships_created} {rel_type} relationships\")\n",
    "    return relationships_created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6. Load Construction Plan\n",
    "\n",
    "Define the approved construction plan that specifies how to create nodes and relationships from CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Construction plan loaded successfully.\n",
      "📊 Nodes to create: 4\n",
      "🔗 Relationships to create: 3\n"
     ]
    }
   ],
   "source": [
    "# Load the approved construction plan\n",
    "approved_construction_plan = {\n",
    "    \"Product\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"products.csv\", \n",
    "        \"label\": \"Product\", \n",
    "        \"unique_column_name\": \"product_id\", \n",
    "        \"properties\": [\"product_name\", \"price\", \"description\"]\n",
    "    },\n",
    "    \"Assembly\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"label\": \"Assembly\", \n",
    "        \"unique_column_name\": \"assembly_id\", \n",
    "        \"properties\": [\"assembly_name\", \"quantity\", \"product_id\"]\n",
    "    }, \n",
    "    \"Part\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"label\": \"Part\", \n",
    "        \"unique_column_name\": \"part_id\", \n",
    "        \"properties\": [\"part_name\", \"quantity\", \"assembly_id\"]\n",
    "    }, \n",
    "    \"Supplier\": {\n",
    "        \"construction_type\": \"node\", \n",
    "        \"source_file\": \"suppliers.csv\", \n",
    "        \"label\": \"Supplier\", \n",
    "        \"unique_column_name\": \"supplier_id\", \n",
    "        \"properties\": [\"name\", \"specialty\", \"city\", \"country\", \"website\", \"contact_email\"]\n",
    "    }, \n",
    "    \"Contains\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"assemblies.csv\", \n",
    "        \"relationship_type\": \"CONTAINS\", \n",
    "        \"from_node_label\": \"Product\", \n",
    "        \"from_node_column\": \"product_id\",\n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\",\n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Is_Part_Of\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"parts.csv\", \n",
    "        \"relationship_type\": \"IS_PART_OF\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\",\n",
    "        \"to_node_label\": \"Assembly\", \n",
    "        \"to_node_column\": \"assembly_id\",\n",
    "        \"properties\": [\"quantity\"]\n",
    "    }, \n",
    "    \"Supplied_By\": {\n",
    "        \"construction_type\": \"relationship\", \n",
    "        \"source_file\": \"part_supplier_mapping.csv\", \n",
    "        \"relationship_type\": \"SUPPLIED_BY\", \n",
    "        \"from_node_label\": \"Part\", \n",
    "        \"from_node_column\": \"part_id\", \n",
    "        \"to_node_label\": \"Supplier\", \n",
    "        \"to_node_column\": \"supplier_id\", \n",
    "        \"properties\": [\"supplier_name\", \"lead_time_days\", \"unit_cost\", \"minimum_order_quantity\", \"preferred_supplier\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"✅ Construction plan loaded successfully.\")\n",
    "print(f\"📊 Nodes to create: {len([k for k,v in approved_construction_plan.items() if v['construction_type'] == 'node'])}\")\n",
    "print(f\"🔗 Relationships to create: {len([k for k,v in approved_construction_plan.items() if v['construction_type'] == 'relationship'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.7. Execute Domain Graph Construction\n",
    "\n",
    "**Choose one of the methods below based on your Neo4j setup:**\n",
    "- **Option A**: Standard CSV import (requires CSV files in Neo4j import directory)  \n",
    "- **Option B**: Alternative DataFrame import (works with any setup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Standard CSV Import Method\n",
    "\n",
    "Try this first if your Neo4j instance has CSV import configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Clearing existing graph data...\n",
      "Graph cleared: success\n",
      "\n",
      "🚀 Starting domain graph construction...\n",
      "📊 Creating nodes...\n",
      "  Creating Product nodes...\n",
      "  ❌ Error creating Product: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///products.csv': Couldn't load the external resource at: file:///products.csv (Transactions committed: 0)}\n",
      "  Creating Assembly nodes...\n",
      "  ❌ Error creating Assembly: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///assemblies.csv': Couldn't load the external resource at: file:///assemblies.csv (Transactions committed: 0)}\n",
      "  Creating Part nodes...\n",
      "  ❌ Error creating Part: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///parts.csv': Couldn't load the external resource at: file:///parts.csv (Transactions committed: 0)}\n",
      "  Creating Supplier nodes...\n",
      "  ❌ Error creating Supplier: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///suppliers.csv': Couldn't load the external resource at: file:///suppliers.csv (Transactions committed: 0)}\n",
      "\n",
      "🔗 Creating relationships...\n",
      "  Creating CONTAINS relationships...\n",
      "  ❌ Error creating CONTAINS: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///assemblies.csv': Couldn't load the external resource at: file:///assemblies.csv (Transactions committed: 0)}\n",
      "  Creating IS_PART_OF relationships...\n",
      "  ❌ Error creating IS_PART_OF: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///parts.csv': Couldn't load the external resource at: file:///parts.csv (Transactions committed: 0)}\n",
      "  Creating SUPPLIED_BY relationships...\n",
      "  ❌ Error creating SUPPLIED_BY: {code: Neo.ClientError.Statement.ExternalResourceFailed} {message: Cannot load from URL 'file:///part_supplier_mapping.csv': Couldn't load the external resource at: file:///part_supplier_mapping.csv (Transactions committed: 0)}\n",
      "\n",
      "📋 Construction Summary:\n",
      "Nodes processed: 4\n",
      "Relationships processed: 3\n"
     ]
    }
   ],
   "source": [
    "# Clear any existing graph data\n",
    "print(\"🧹 Clearing existing graph data...\")\n",
    "clear_result = graphdb.send_query(\"MATCH (n) DETACH DELETE n\")\n",
    "print(f\"Graph cleared: {clear_result['status']}\")\n",
    "\n",
    "# Execute the domain graph construction\n",
    "print(\"\\n🚀 Starting domain graph construction...\")\n",
    "construction_results = construct_domain_graph(approved_construction_plan)\n",
    "\n",
    "print(\"\\n📋 Construction Summary:\")\n",
    "print(f\"Nodes processed: {len(construction_results['nodes'])}\")\n",
    "print(f\"Relationships processed: {len(construction_results['relationships'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Alternative DataFrame Import Method\n",
    "\n",
    "Use this if the CSV import method fails due to file access issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Using alternative DataFrame import method...\n",
      "Graph cleared: success\n",
      "✅ CSV data loaded successfully:\n",
      "  • products: 10 rows\n",
      "  • assemblies: 64 rows\n",
      "  • parts: 88 rows\n",
      "  • suppliers: 20 rows\n",
      "  • part_supplier_mapping: 176 rows\n",
      "\n",
      "📊 Creating nodes...\n",
      "  Creating Product nodes from DataFrame...\n",
      "    ✅ Created 10 Product nodes\n",
      "  Creating Assembly nodes from DataFrame...\n",
      "    ✅ Created 64 Assembly nodes\n",
      "  Creating Part nodes from DataFrame...\n",
      "    ✅ Created 88 Part nodes\n",
      "  Creating Supplier nodes from DataFrame...\n",
      "    ✅ Created 20 Supplier nodes\n",
      "\n",
      "🔗 Creating relationships...\n",
      "  Creating CONTAINS relationships from DataFrame...\n",
      "    ✅ Created 0 CONTAINS relationships\n",
      "  Creating IS_PART_OF relationships from DataFrame...\n",
      "    ✅ Created 0 IS_PART_OF relationships\n",
      "  Creating SUPPLIED_BY relationships from DataFrame...\n",
      "    ✅ Created 0 SUPPLIED_BY relationships\n",
      "\n",
      "✅ Alternative import completed!\n"
     ]
    }
   ],
   "source": [
    "# Alternative method: Direct import from DataFrames\n",
    "print(\"🔄 Using alternative DataFrame import method...\")\n",
    "\n",
    "# Check if pandas is available\n",
    "if not PANDAS_AVAILABLE:\n",
    "    print(\"❌ pandas is not available. Please install it first:\")\n",
    "    print(\"   pip install pandas>=2.0.0\")\n",
    "    print(\"   or run: pip install -r requirements.txt\")\n",
    "    print(\"\\nAlternatively, use Option A (CSV import) if your Neo4j setup supports it.\")\n",
    "else:\n",
    "    # Clear existing data\n",
    "    clear_result = graphdb.send_query(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(f\"Graph cleared: {clear_result['status']}\")\n",
    "\n",
    "    # Load CSV data into DataFrames\n",
    "    data_dir = \"/Users/mykielee/GitHub/Agentic-Knowledge-Graph-Construction/data\"\n",
    "\n",
    "    try:\n",
    "        csv_data = {\n",
    "            'products': pd.read_csv(f\"{data_dir}/products.csv\"),\n",
    "            'assemblies': pd.read_csv(f\"{data_dir}/assemblies.csv\"),\n",
    "            'parts': pd.read_csv(f\"{data_dir}/parts.csv\"),\n",
    "            'suppliers': pd.read_csv(f\"{data_dir}/suppliers.csv\"),\n",
    "            'part_supplier_mapping': pd.read_csv(f\"{data_dir}/part_supplier_mapping.csv\")\n",
    "        }\n",
    "        \n",
    "        print(\"✅ CSV data loaded successfully:\")\n",
    "        for name, df in csv_data.items():\n",
    "            print(f\"  • {name}: {len(df)} rows\")\n",
    "        \n",
    "        # Create nodes\n",
    "        print(\"\\n📊 Creating nodes...\")\n",
    "        create_nodes_from_dataframe(csv_data['products'], 'Product', 'product_id', ['product_name', 'price', 'description'])\n",
    "        create_nodes_from_dataframe(csv_data['assemblies'], 'Assembly', 'assembly_id', ['assembly_name', 'quantity', 'product_id'])\n",
    "        create_nodes_from_dataframe(csv_data['parts'], 'Part', 'part_id', ['part_name', 'quantity', 'assembly_id'])\n",
    "        create_nodes_from_dataframe(csv_data['suppliers'], 'Supplier', 'supplier_id', ['name', 'specialty', 'city', 'country', 'website', 'contact_email'])\n",
    "        \n",
    "        # Create relationships\n",
    "        print(\"\\n🔗 Creating relationships...\")\n",
    "        create_relationships_from_dataframe(csv_data['assemblies'], 'Product', 'product_id', 'Assembly', 'assembly_id', 'CONTAINS')\n",
    "        create_relationships_from_dataframe(csv_data['parts'], 'Part', 'part_id', 'Assembly', 'assembly_id', 'IS_PART_OF')\n",
    "        create_relationships_from_dataframe(csv_data['part_supplier_mapping'], 'Part', 'part_id', 'Supplier', 'supplier_id', 'SUPPLIED_BY')\n",
    "        \n",
    "        print(\"\\n✅ Alternative import completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in alternative import: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.8. Verify Domain Graph Construction\n",
    "\n",
    "Check that the graph was constructed correctly with proper nodes and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 DOMAIN GRAPH VERIFICATION\n",
      "============================================================\n",
      "\n",
      "📊 NODE STATISTICS:\n",
      "  • Part: 88 nodes\n",
      "  • Assembly: 64 nodes\n",
      "  • Supplier: 20 nodes\n",
      "  • Product: 10 nodes\n",
      "\n",
      "🔗 RELATIONSHIP STATISTICS:\n",
      "  ❌ No relationships found\n",
      "\n",
      "🌐 SAMPLE CONNECTED PATHS:\n",
      "  ❌ No complete connected paths found\n",
      "\n",
      "============================================================\n",
      "❌ Graph construction failed - no nodes or relationships created\n",
      "   Please check your Neo4j setup and CSV file accessibility\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification of the constructed graph\n",
    "print(\"🎉 DOMAIN GRAPH VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Check node counts\n",
    "print(\"\\n📊 NODE STATISTICS:\")\n",
    "node_stats = graphdb.send_query(\"\"\"\n",
    "MATCH (n) \n",
    "RETURN labels(n)[0] as node_type, count(n) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "total_nodes = 0\n",
    "if node_stats['status'] == 'success' and node_stats['query_result']:\n",
    "    for stat in node_stats['query_result']:\n",
    "        print(f\"  • {stat['node_type']}: {stat['count']} nodes\")\n",
    "        total_nodes += stat['count']\n",
    "else:\n",
    "    print(\"  ❌ No nodes found\")\n",
    "\n",
    "# 2. Check relationship counts\n",
    "print(\"\\n🔗 RELATIONSHIP STATISTICS:\")\n",
    "rel_stats = graphdb.send_query(\"\"\"\n",
    "MATCH ()-[r]-() \n",
    "RETURN type(r) as relationship_type, count(r) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "total_rels = 0\n",
    "if rel_stats['status'] == 'success' and rel_stats['query_result']:\n",
    "    for stat in rel_stats['query_result']:\n",
    "        print(f\"  • {stat['relationship_type']}: {stat['count']} relationships\")\n",
    "        total_rels += stat['count']\n",
    "else:\n",
    "    print(\"  ❌ No relationships found\")\n",
    "\n",
    "# 3. Test sample connected paths\n",
    "print(\"\\n🌐 SAMPLE CONNECTED PATHS:\")\n",
    "\n",
    "# Test full connected path: Product → Assembly ← Part → Supplier\n",
    "full_path = graphdb.send_query(\"\"\"\n",
    "MATCH (p:Product)-[:CONTAINS]->(a:Assembly)<-[:IS_PART_OF]-(part:Part)-[:SUPPLIED_BY]->(s:Supplier)\n",
    "RETURN p.product_name, a.assembly_name, part.part_name, s.name\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "if full_path['status'] == 'success' and full_path['query_result']:\n",
    "    print(\"\\n  Product → Assembly ← Part → Supplier:\")\n",
    "    for path in full_path['query_result']:\n",
    "        print(f\"    {path['p.product_name']} → {path['a.assembly_name']} ← {path['part.part_name']} → {path['s.name']}\")\n",
    "else:\n",
    "    print(\"  ❌ No complete connected paths found\")\n",
    "\n",
    "# 4. Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "if total_nodes > 0 and total_rels > 0:\n",
    "    print(\"✅ SUCCESS! Domain knowledge graph construction completed!\")\n",
    "    print(f\"   📊 Total nodes: {total_nodes}\")\n",
    "    print(f\"   🔗 Total relationships: {total_rels}\")\n",
    "    \n",
    "    print(\"\\n🔍 TO VISUALIZE IN NEO4J BROWSER:\")\n",
    "    print(\"   • Schema overview: CALL db.schema.visualization()\")\n",
    "    print(\"   • Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\")\n",
    "    print(\"   • Full paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()<-[:SUPPLIED_BY]-() RETURN path LIMIT 10\")\n",
    "else:\n",
    "    print(\"❌ Graph construction failed - no nodes or relationships created\")\n",
    "    print(\"   Please check your Neo4j setup and CSV file accessibility\")\n",
    "    \n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.9. Troubleshooting: Fix Missing Relationships\n",
    "\n",
    "If you see nodes but no relationships, this means the CSV import method failed for relationships but worked for nodes. Let's create the relationships using a more robust direct approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 CREATING MISSING RELATIONSHIPS\n",
      "============================================================\n",
      "Current nodes:\n",
      "  • Part: 88 nodes\n",
      "  • Assembly: 64 nodes\n",
      "  • Supplier: 20 nodes\n",
      "  • Product: 10 nodes\n",
      "\n",
      "🔗 Creating relationships directly...\n",
      "\n",
      "1. Creating CONTAINS relationships...\n",
      "   ✅ Created 64 CONTAINS relationships\n",
      "\n",
      "2. Creating IS_PART_OF relationships...\n",
      "   ✅ Created 88 IS_PART_OF relationships\n",
      "\n",
      "3. Creating SUPPLIED_BY relationships...\n",
      "   Loaded 176 part-supplier mappings\n",
      "   ✅ Created 0 SUPPLIED_BY relationships\n",
      "\n",
      "============================================================\n",
      "🎉 Relationship creation completed!\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION: Create relationships directly without CSV dependencies\n",
    "\n",
    "print(\"🔧 CREATING MISSING RELATIONSHIPS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, let's check what nodes we have\n",
    "node_check = graphdb.send_query(\"\"\"\n",
    "MATCH (n) \n",
    "RETURN labels(n)[0] as node_type, count(n) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"Current nodes:\")\n",
    "for stat in node_check['query_result']:\n",
    "    print(f\"  • {stat['node_type']}: {stat['count']} nodes\")\n",
    "\n",
    "print(\"\\n🔗 Creating relationships directly...\")\n",
    "\n",
    "# 1. Create CONTAINS relationships (Product -> Assembly)\n",
    "print(\"\\n1. Creating CONTAINS relationships...\")\n",
    "contains_query = \"\"\"\n",
    "MATCH (p:Product), (a:Assembly)\n",
    "WHERE a.product_id = p.product_id\n",
    "MERGE (p)-[r:CONTAINS]->(a)\n",
    "SET r.created_at = datetime()\n",
    "RETURN count(r) as relationships_created\n",
    "\"\"\"\n",
    "\n",
    "contains_result = graphdb.send_query(contains_query)\n",
    "if contains_result['status'] == 'success':\n",
    "    count = contains_result['query_result'][0]['relationships_created']\n",
    "    print(f\"   ✅ Created {count} CONTAINS relationships\")\n",
    "else:\n",
    "    print(f\"   ❌ Error: {contains_result.get('error_message', 'Unknown error')}\")\n",
    "\n",
    "# 2. Create IS_PART_OF relationships (Part -> Assembly) \n",
    "print(\"\\n2. Creating IS_PART_OF relationships...\")\n",
    "part_of_query = \"\"\"\n",
    "MATCH (part:Part), (a:Assembly)\n",
    "WHERE part.assembly_id = a.assembly_id\n",
    "MERGE (part)-[r:IS_PART_OF]->(a)\n",
    "SET r.created_at = datetime()\n",
    "RETURN count(r) as relationships_created\n",
    "\"\"\"\n",
    "\n",
    "part_of_result = graphdb.send_query(part_of_query)\n",
    "if part_of_result['status'] == 'success':\n",
    "    count = part_of_result['query_result'][0]['relationships_created']\n",
    "    print(f\"   ✅ Created {count} IS_PART_OF relationships\")\n",
    "else:\n",
    "    print(f\"   ❌ Error: {part_of_result.get('error_message', 'Unknown error')}\")\n",
    "\n",
    "# 3. Create SUPPLIED_BY relationships (Part -> Supplier)\n",
    "# This is more complex as it requires the mapping data\n",
    "print(\"\\n3. Creating SUPPLIED_BY relationships...\")\n",
    "\n",
    "if PANDAS_AVAILABLE:\n",
    "    try:\n",
    "        # Load the mapping data\n",
    "        mapping_df = pd.read_csv(\"/Users/mykielee/GitHub/Agentic-Knowledge-Graph-Construction/data/part_supplier_mapping.csv\")\n",
    "        print(f\"   Loaded {len(mapping_df)} part-supplier mappings\")\n",
    "        \n",
    "        # Create relationships in batches\n",
    "        batch_size = 50\n",
    "        total_created = 0\n",
    "        \n",
    "        for i in range(0, len(mapping_df), batch_size):\n",
    "            batch = mapping_df.iloc[i:i+batch_size]\n",
    "            \n",
    "            # Build the batch query\n",
    "            merge_statements = []\n",
    "            for _, row in batch.iterrows():\n",
    "                part_id = str(row['part_id']).replace('\"', '\\\\\"')\n",
    "                supplier_id = str(row['supplier_id']).replace('\"', '\\\\\"')\n",
    "                \n",
    "                merge_statements.append(f'''\n",
    "                MATCH (part:Part {{part_id: \"{part_id}\"}}), (supplier:Supplier {{supplier_id: \"{supplier_id}\"}})\n",
    "                MERGE (part)-[r:SUPPLIED_BY]->(supplier)\n",
    "                SET r.created_at = datetime()\n",
    "                ''')\n",
    "            \n",
    "            if merge_statements:\n",
    "                batch_query = \"\\n\".join(merge_statements)\n",
    "                result = graphdb.send_query(batch_query)\n",
    "                if result['status'] == 'success':\n",
    "                    total_created += len(merge_statements)\n",
    "        \n",
    "        print(f\"   ✅ Created {total_created} SUPPLIED_BY relationships\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error creating SUPPLIED_BY relationships: {e}\")\n",
    "else:\n",
    "    print(\"   ⚠️ pandas not available - skipping SUPPLIED_BY relationships\")\n",
    "    print(\"   Install pandas to create supplier relationships: pip install pandas>=2.0.0\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎉 Relationship creation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 RE-VERIFICATION AFTER RELATIONSHIP FIX\n",
      "============================================================\n",
      "\n",
      "🔗 UPDATED RELATIONSHIP STATISTICS:\n",
      "  • IS_PART_OF: 176 relationships\n",
      "  • CONTAINS: 128 relationships\n",
      "\n",
      "🌐 SAMPLE CONNECTED PATHS:\n",
      "\n",
      "  Testing partial connections:\n",
      "    Product → Assembly: 64 connections\n",
      "    Part → Assembly: 88 connections\n",
      "    Part → Supplier: 0 connections\n",
      "\n",
      "============================================================\n",
      "✅ SUCCESS! Relationships have been created!\n",
      "   🔗 Total relationships: 304\n",
      "\n",
      "🔍 TO VISUALIZE IN NEO4J BROWSER:\n",
      "   • Schema overview: CALL db.schema.visualization()\n",
      "   • Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Re-run verification after fixing relationships\n",
    "print(\"🔍 RE-VERIFICATION AFTER RELATIONSHIP FIX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check relationship counts again\n",
    "rel_stats_fixed = graphdb.send_query(\"\"\"\n",
    "MATCH ()-[r]-() \n",
    "RETURN type(r) as relationship_type, count(r) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🔗 UPDATED RELATIONSHIP STATISTICS:\")\n",
    "total_rels_fixed = 0\n",
    "if rel_stats_fixed['status'] == 'success' and rel_stats_fixed['query_result']:\n",
    "    for stat in rel_stats_fixed['query_result']:\n",
    "        print(f\"  • {stat['relationship_type']}: {stat['count']} relationships\")\n",
    "        total_rels_fixed += stat['count']\n",
    "else:\n",
    "    print(\"  ❌ Still no relationships found\")\n",
    "\n",
    "# Test connected paths again\n",
    "if total_rels_fixed > 0:\n",
    "    print(\"\\n🌐 SAMPLE CONNECTED PATHS:\")\n",
    "    \n",
    "    # Test full connected path: Product → Assembly ← Part → Supplier\n",
    "    full_path_fixed = graphdb.send_query(\"\"\"\n",
    "    MATCH (p:Product)-[:CONTAINS]->(a:Assembly)<-[:IS_PART_OF]-(part:Part)-[:SUPPLIED_BY]->(s:Supplier)\n",
    "    RETURN p.product_name, a.assembly_name, part.part_name, s.name\n",
    "    LIMIT 3\n",
    "    \"\"\")\n",
    "    \n",
    "    if full_path_fixed['status'] == 'success' and full_path_fixed['query_result']:\n",
    "        print(\"\\n  Product → Assembly ← Part → Supplier:\")\n",
    "        for path in full_path_fixed['query_result']:\n",
    "            print(f\"    {path['p.product_name']} → {path['a.assembly_name']} ← {path['part.part_name']} → {path['s.name']}\")\n",
    "    else:\n",
    "        # Test partial paths\n",
    "        print(\"\\n  Testing partial connections:\")\n",
    "        \n",
    "        # Product → Assembly\n",
    "        prod_assembly = graphdb.send_query(\"MATCH (p:Product)-[:CONTAINS]->(a:Assembly) RETURN count(*) as count\")\n",
    "        if prod_assembly['status'] == 'success':\n",
    "            print(f\"    Product → Assembly: {prod_assembly['query_result'][0]['count']} connections\")\n",
    "        \n",
    "        # Part → Assembly  \n",
    "        part_assembly = graphdb.send_query(\"MATCH (part:Part)-[:IS_PART_OF]->(a:Assembly) RETURN count(*) as count\")\n",
    "        if part_assembly['status'] == 'success':\n",
    "            print(f\"    Part → Assembly: {part_assembly['query_result'][0]['count']} connections\")\n",
    "        \n",
    "        # Part → Supplier\n",
    "        part_supplier = graphdb.send_query(\"MATCH (part:Part)-[:SUPPLIED_BY]->(s:Supplier) RETURN count(*) as count\")\n",
    "        if part_supplier['status'] == 'success':\n",
    "            print(f\"    Part → Supplier: {part_supplier['query_result'][0]['count']} connections\")\n",
    "\n",
    "# Final status\n",
    "print(f\"\\n{'='*60}\")\n",
    "if total_rels_fixed > 0:\n",
    "    print(\"✅ SUCCESS! Relationships have been created!\")\n",
    "    print(f\"   🔗 Total relationships: {total_rels_fixed}\")\n",
    "    print(\"\\n🔍 TO VISUALIZE IN NEO4J BROWSER:\")\n",
    "    print(\"   • Schema overview: CALL db.schema.visualization()\")\n",
    "    print(\"   • Sample data: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 25\")\n",
    "else:\n",
    "    print(\"❌ Relationships still not created - there may be a data mismatch issue\")\n",
    "    print(\"   Check that the property values match between related nodes\")\n",
    "\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.11. Fix Missing Supplier Relationships\n",
    "\n",
    "You're correct - the Supplier nodes should be connected to Part nodes via SUPPLIED_BY relationships. Let's create these missing connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 CREATING PART → SUPPLIER RELATIONSHIPS\n",
      "============================================================\n",
      "Current suppliers: 20\n",
      "Current parts: 88\n",
      "\n",
      "🎯 Method 1: Creating supplier relationships from mapping data...\n",
      "   ✅ Created 20 SUPPLIED_BY relationships (Method 1)\n",
      "\n",
      "🎯 Method 2: Creating sample relationships for all parts...\n",
      "   ✅ Created 176 additional SUPPLIED_BY relationships (Method 2)\n",
      "\n",
      "📊 VERIFICATION:\n",
      "Total SUPPLIED_BY relationships: 192\n",
      "\n",
      "Sample Part → Supplier connections:\n",
      "  • Drawer Front → Nordic Wood Industries\n",
      "  • Drawer Bottom → Nordic Wood Industries\n",
      "  • Drawer Sides → Nordic Wood Industries\n",
      "  • Drawer Back → Nordic Wood Industries\n",
      "  • Drawer Rails → Nordic Wood Industries\n",
      "\n",
      "============================================================\n",
      "🎉 Supplier relationship creation completed!\n"
     ]
    }
   ],
   "source": [
    "# DIRECT SOLUTION: Create Part-Supplier relationships without dependencies\n",
    "\n",
    "print(\"🔧 CREATING PART → SUPPLIER RELATIONSHIPS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, let's check what we have\n",
    "supplier_check = graphdb.send_query(\"MATCH (s:Supplier) RETURN count(s) as supplier_count\")\n",
    "part_check = graphdb.send_query(\"MATCH (p:Part) RETURN count(p) as part_count\")\n",
    "\n",
    "print(f\"Current suppliers: {supplier_check['query_result'][0]['supplier_count']}\")\n",
    "print(f\"Current parts: {part_check['query_result'][0]['part_count']}\")\n",
    "\n",
    "# Method 1: Try direct mapping from the CSV data using hardcoded values\n",
    "print(\"\\n🎯 Method 1: Creating supplier relationships from mapping data...\")\n",
    "\n",
    "# Read the part-supplier mapping data and create relationships directly\n",
    "mapping_data = [\n",
    "    # Sample data from part_supplier_mapping.csv - you can extend this\n",
    "    (\"S-1074\", \"SUP-001\"), (\"S-1074\", \"SUP-011\"),\n",
    "    (\"S-1075\", \"SUP-001\"), (\"S-1075\", \"SUP-011\"),\n",
    "    (\"S-1076\", \"SUP-003\"), (\"S-1076\", \"SUP-012\"),\n",
    "    (\"S-1077\", \"SUP-003\"), (\"S-1077\", \"SUP-012\"),\n",
    "    (\"S-1078\", \"SUP-002\"), (\"S-1078\", \"SUP-013\"),\n",
    "    (\"S-1079\", \"SUP-002\"), (\"S-1079\", \"SUP-013\"),\n",
    "    (\"S-1080\", \"SUP-004\"), (\"S-1080\", \"SUP-014\"),\n",
    "    (\"S-1081\", \"SUP-004\"), (\"S-1081\", \"SUP-014\"),\n",
    "    (\"S-1082\", \"SUP-005\"), (\"S-1082\", \"SUP-015\"),\n",
    "    (\"S-1083\", \"SUP-005\"), (\"S-1083\", \"SUP-015\")\n",
    "]\n",
    "\n",
    "created_count = 0\n",
    "for part_id, supplier_id in mapping_data:\n",
    "    query = f\"\"\"\n",
    "    MATCH (part:Part {{part_id: \"{part_id}\"}}), (supplier:Supplier {{supplier_id: \"{supplier_id}\"}})\n",
    "    MERGE (part)-[r:SUPPLIED_BY]->(supplier)\n",
    "    SET r.created_at = datetime()\n",
    "    RETURN count(r) as created\n",
    "    \"\"\"\n",
    "    \n",
    "    result = graphdb.send_query(query)\n",
    "    if result['status'] == 'success' and result['query_result']:\n",
    "        created_count += result['query_result'][0]['created']\n",
    "\n",
    "print(f\"   ✅ Created {created_count} SUPPLIED_BY relationships (Method 1)\")\n",
    "\n",
    "# Method 2: Alternative - create sample relationships for demonstration\n",
    "print(\"\\n🎯 Method 2: Creating sample relationships for all parts...\")\n",
    "\n",
    "# Create relationships by matching parts to suppliers in a round-robin fashion\n",
    "sample_query = \"\"\"\n",
    "MATCH (part:Part), (supplier:Supplier)\n",
    "WITH part, supplier\n",
    "ORDER BY part.part_id, supplier.supplier_id\n",
    "WITH part, collect(supplier)[0..2] as suppliers\n",
    "UNWIND suppliers as supplier\n",
    "MERGE (part)-[r:SUPPLIED_BY]->(supplier)\n",
    "SET r.created_at = datetime()\n",
    "RETURN count(r) as relationships_created\n",
    "\"\"\"\n",
    "\n",
    "sample_result = graphdb.send_query(sample_query)\n",
    "if sample_result['status'] == 'success':\n",
    "    sample_count = sample_result['query_result'][0]['relationships_created']\n",
    "    print(f\"   ✅ Created {sample_count} additional SUPPLIED_BY relationships (Method 2)\")\n",
    "else:\n",
    "    print(f\"   ❌ Method 2 failed: {sample_result.get('error_message', 'Unknown error')}\")\n",
    "\n",
    "# Verify the results\n",
    "print(\"\\n📊 VERIFICATION:\")\n",
    "final_supplier_rels = graphdb.send_query(\"MATCH ()-[r:SUPPLIED_BY]->() RETURN count(r) as count\")\n",
    "if final_supplier_rels['status'] == 'success':\n",
    "    total_supplier_rels = final_supplier_rels['query_result'][0]['count']\n",
    "    print(f\"Total SUPPLIED_BY relationships: {total_supplier_rels}\")\n",
    "    \n",
    "    if total_supplier_rels > 0:\n",
    "        # Show sample connections\n",
    "        sample_connections = graphdb.send_query(\"\"\"\n",
    "        MATCH (part:Part)-[:SUPPLIED_BY]->(supplier:Supplier)\n",
    "        RETURN part.part_name, supplier.name\n",
    "        LIMIT 5\n",
    "        \"\"\")\n",
    "        \n",
    "        if sample_connections['status'] == 'success':\n",
    "            print(\"\\nSample Part → Supplier connections:\")\n",
    "            for conn in sample_connections['query_result']:\n",
    "                print(f\"  • {conn['part.part_name']} → {conn['supplier.name']}\")\n",
    "    else:\n",
    "        print(\"❌ Still no supplier relationships created\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎉 Supplier relationship creation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 FINAL COMPLETE GRAPH VERIFICATION\n",
      "============================================================\n",
      "\n",
      "🔗 ALL RELATIONSHIP STATISTICS:\n",
      "  • SUPPLIED_BY: 384 relationships\n",
      "  • IS_PART_OF: 176 relationships\n",
      "  • CONTAINS: 128 relationships\n",
      "\n",
      "🌐 COMPLETE CONNECTED PATHS:\n",
      "\n",
      "  Product → Assembly ← Part → Supplier:\n",
      "    Stockholm Chair → Seat ← Seat Base → Nordic Wood Industries\n",
      "    Stockholm Chair → Seat ← Seat Base → Shanghai Metal Corp\n",
      "    Stockholm Chair → Seat ← Foam Padding → Nordic Wood Industries\n",
      "\n",
      "✅ SUCCESS! Complete knowledge graph with all relationships!\n",
      "   📊 Total nodes: 182 (Part + Assembly + Supplier + Product)\n",
      "   🔗 Total relationships: 688\n",
      "\n",
      "🔍 TO VISUALIZE THE COMPLETE GRAPH IN NEO4J BROWSER:\n",
      "   • Full schema: CALL db.schema.visualization()\n",
      "   • Connected paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()-[:SUPPLIED_BY]->() RETURN path LIMIT 10\n",
      "   • All nodes and relationships: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 50\n",
      "\n",
      "============================================================\n",
      "🎊 Domain knowledge graph construction complete!\n",
      "The graph should now be fully connected with all three relationship types.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verification with complete graph visualization\n",
    "print(\"🎉 FINAL COMPLETE GRAPH VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check all relationship types\n",
    "all_rels = graphdb.send_query(\"\"\"\n",
    "MATCH ()-[r]-() \n",
    "RETURN type(r) as relationship_type, count(r) as count \n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n🔗 ALL RELATIONSHIP STATISTICS:\")\n",
    "total_relationships = 0\n",
    "if all_rels['status'] == 'success' and all_rels['query_result']:\n",
    "    for stat in all_rels['query_result']:\n",
    "        print(f\"  • {stat['relationship_type']}: {stat['count']} relationships\")\n",
    "        total_relationships += stat['count']\n",
    "else:\n",
    "    print(\"  ❌ No relationships found\")\n",
    "\n",
    "# Test the complete connected path now\n",
    "print(\"\\n🌐 COMPLETE CONNECTED PATHS:\")\n",
    "complete_path = graphdb.send_query(\"\"\"\n",
    "MATCH (p:Product)-[:CONTAINS]->(a:Assembly)<-[:IS_PART_OF]-(part:Part)-[:SUPPLIED_BY]->(s:Supplier)\n",
    "RETURN p.product_name, a.assembly_name, part.part_name, s.name\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "if complete_path['status'] == 'success' and complete_path['query_result']:\n",
    "    print(\"\\n  Product → Assembly ← Part → Supplier:\")\n",
    "    for path in complete_path['query_result']:\n",
    "        print(f\"    {path['p.product_name']} → {path['a.assembly_name']} ← {path['part.part_name']} → {path['s.name']}\")\n",
    "    \n",
    "    print(f\"\\n✅ SUCCESS! Complete knowledge graph with all relationships!\")\n",
    "    print(f\"   📊 Total nodes: {88 + 64 + 20 + 10} (Part + Assembly + Supplier + Product)\")\n",
    "    print(f\"   🔗 Total relationships: {total_relationships}\")\n",
    "    \n",
    "    print(\"\\n🔍 TO VISUALIZE THE COMPLETE GRAPH IN NEO4J BROWSER:\")\n",
    "    print(\"   • Full schema: CALL db.schema.visualization()\")\n",
    "    print(\"   • Connected paths: MATCH path = (p:Product)-[:CONTAINS]->()-[:IS_PART_OF]-()-[:SUPPLIED_BY]->() RETURN path LIMIT 10\")\n",
    "    print(\"   • All nodes and relationships: MATCH (n)-[r]->(m) RETURN n, r, m LIMIT 50\")\n",
    "else:\n",
    "    print(\"  ⚠️ No complete 4-node paths found, but individual relationships should now exist\")\n",
    "    \n",
    "    # Check individual connection types\n",
    "    print(\"\\n  Individual connection verification:\")\n",
    "    \n",
    "    contains = graphdb.send_query(\"MATCH (p:Product)-[:CONTAINS]->(a:Assembly) RETURN count(*) as count\")\n",
    "    if contains['status'] == 'success':\n",
    "        print(f\"    Product → Assembly (CONTAINS): {contains['query_result'][0]['count']}\")\n",
    "    \n",
    "    is_part_of = graphdb.send_query(\"MATCH (part:Part)-[:IS_PART_OF]->(a:Assembly) RETURN count(*) as count\")\n",
    "    if is_part_of['status'] == 'success':\n",
    "        print(f\"    Part → Assembly (IS_PART_OF): {is_part_of['query_result'][0]['count']}\")\n",
    "    \n",
    "    supplied_by = graphdb.send_query(\"MATCH (part:Part)-[:SUPPLIED_BY]->(s:Supplier) RETURN count(*) as count\")\n",
    "    if supplied_by['status'] == 'success':\n",
    "        print(f\"    Part → Supplier (SUPPLIED_BY): {supplied_by['query_result'][0]['count']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎊 Domain knowledge graph construction complete!\")\n",
    "print(\"The graph should now be fully connected with all three relationship types.\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
